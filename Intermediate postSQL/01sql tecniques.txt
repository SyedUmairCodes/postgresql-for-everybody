# Welcome to Intermediate SQL!

Hello and welcome to Postgres for Everybody Intermediate SQL. Remember I said that the fun part of this course was when I could get beyond CRUD, get beyond the basics. So here we are in the second part of the course, and now we're beyond the basics. We're going to go round two of what I call like the next set of steps or the next set of basic skills. The weird thing is, I spent a lot of time thinking about what is a core thing, and there's this extra set of things. And the weird thing is, I don't exactly know what order even to do all this stuff. There's, like, just more things. And so we're just going to sort of zoom through and just talk. I mean, here's a thing you gotta know, here's a thing you gotta know, here's a thing you gotta know. And then later we'll do assignments that use all those techniques. And so we'll learn about things like group by and stored procedures and subqueries and aggregation and transactions. And just trust me. You need them all. I may not be able to give you assignments or like here is the subquery assignment. But then when we do it later we'll be like, okay, we've got to do select distinct and subquery and this other thing. And so what happens is that it's really hard to make assignments that just use one technique, and so you'll see the assignments just tend to assume you know stuff. So the first part is to get you to know all those things, and then we start doing assignments that use all those things. So I hope you're going to enjoy some of these next set of basic skills.

# Altering Table Schema
So the first topic I want to talk about is what we do after a CREATE TABLE. And so up till now I keep talking about like, oh, the CREATE TABLE and you've got to get it right and if you get the columns too short, then you're in bad shape. That's not exactly true, right? You can absolutely make mistakes. Like in this one, the content, I'm making some blog posts, and the content I make is 1,000 characters and you might make a database table and think, well, my little paragraphs are going to be 1,000 characters and about that much text fits nicely into 1,000 characters. But then someone types more, and you're like, "Oh crap, 1,000 characters is not enough." And you're like, "Oh, now what do I do?" Well, it turns out that this ALTER TABLE capability in most competent databases is amazing. Meaning that you can change the schema and it will auto convert all of the data to the new schema all while the application is running. And even though we're doing data mining, so you're not always working with a live database, literally if you are building an online system, because you might actually be talking to a database where there is a front end to it, but you're like talking to the back end, it can do an ALTER TABLE while it's live. Now, you've got to be careful because if you're like taking a column out or adding a column in, then if the application starts sending data to a column that you just removed, then that part will blow up. But in this case, I made my content a VARCHAR 1024, and it's like, no, that's not right, but I could easily fix that with an ALTER TABLE Another kind of thing that you might do is you wouldn't name your column oops, but you might be copying and pasting. And I do this all the time. You might be copying and pasting your CREATE statements, and then you leave something in, like in the favorites. And so the comments, there's a text area and the favorites is a number, but I copied and pasted. I was in too much of a hurry and so I left the text thing in, but I forgot to add a number and I'm like, "Am I doomed?" And actually the application has already started and it's actually started to load data and you've got to fix it. Well, the good news is that's the ALTER TABLE. We make a mistake in a schema or the schema is going to evolve, and so we create it. And even though these two look like they happen one right after another, I mean, ALTER TABLE DROP COLUMN oops could happen days or weeks or months later. And once the database starts altering it and doing that work, it's fine. And again, if nothing is looking for or storing stuff into this column oops, then we're good. And so again, you can do this on live databases. And so the little mistakes I made is I added a column so you can drop a column. I had a column called content that was VARCHAR 1024 and it really needs to be TEXT so it could be unlimited length, and I forgot to set the column fav, which is how much you like something, and it's an integer. So you can add a column, you can drop a column, you can change a column. And it doesn't all have to be columns. If you have like a foreign key relationship and you got it wrong, or uniqueness constraints. Sometimes you make a uniqueness constraint and you need to have two of your columns unique instead of one column and you just, like, change it. And you've got to like drop the constraints sometimes and then add a new constraint. But go talk to StackOverflow and say, "How do I change a constraint in a Postgres database?" And they will be like, Alter Table or sometimes drop constraint or whatever. And like I said, I love the fact that it can run on a live database. Another technique that we're going to use is the basic notion of reading SQL statements from a file. And so I can hand you, and I do hand you, some of these files. Usually when I'm giving you the main file for the lecture, I kind of want you to cut and paste and see what each thing does. But what if I'm going to load 1,000 records? Well, I'll just give you the insert statements in a text file with 1,000 insert statements or an insert statement with 1,000 values. And you're like, I want to run this file and so you just say \i, and then you give the file name. In this case, you would have downloaded it into the same folder as you are running your psql command. Okay, so that's changing the schema and running scripts. And up next we're going to talk about how we handle dates. Dates are a real important part of databases.

# Dates

So dates are an important part of databases. It's important to think about dates in two ways. There's kind of like the date and the time, I almost think of them as like string fields. If you're entering historical data, what are the significant events of the Civil War in the United States, right? And so, okay, this happened in 1862, and '63, and '64. Those are like historical dates and no one's arguing about like what time zone or what time of day they were. And so DATE and TIME are just things that you're reading and you're typing in and it's not time zone. They're sort of like what was written down at the time that something happened. Whereas, in computers, when we're doing things like you type in a blog post and you send it and it says two hours ago later, well, that's what I call a when time, right? That's when did something happen. And the key thing about the difference between a date and a time, and a time stamp, which is more of a when concept, when did something happen concept, is that the moment that I hit this key, is a moment in time that is simultaneously the same moment in time in all the time zones of the world at the same time. So if you start a meeting and you say, "Hello everybody" that might be five o'clock in the East Coast United States, it might be two o'clock in the West Coast United States, and it might be 11 o'clock in England. And it's still the same moment, the same when. And so we use time stamps. Now, there's two kinds of time stamps. One I find almost useless and then the other one is a time stamp with a time zone. They're both eight-byte fields in Postgres, and for me, I just use TIMESTAMPTZ all the time. Now, the interesting thing about TIMESTAMPTZ is you can actually store a time zone in US Eastern Time and it knows, okay, this is one o'clock in the afternoon, US Eastern Time. And then if you pull it out, you can see it in US Pacific Time or British Standard Time, or whatever. There is this PostgresSQL function most all databases generally have this function called NOW, which is within whatever time zone it's at perhaps told to be in the Universal Time Zone, which is Greenwich Mean Time-ish, that is now. And that's this moment in time, right this minute, and it has a time zone associated with it generally. So we tend to put in our databases lots of these TIMESTAMPTZs. Now, other databases don't have this TIMESTAMPTZ, but this is necessary in Postgres. And so the other thing that you'll notice is that we have this little bit of text called DEFAULT NOW, right? This NOT NULL DEFAULT NOW. And this is kind of like a constraint or a unique key or whatever. We're talking in our schema definition, our CREATE statement, we are talking about what we want the database to do for us automatically. And so if you look at any database I created in the last 10 years, I always have a created_at which is either TIMESTAMP for some databases or TIMESTAMPTZ in Postgres, that has a automatically generated. When you insert the row, put the current time in, don't make me put that in every INSERT statement. So I name it a particular way and I give it the database an instruction as to how to pre-populate it. Now, we'll talk about updated_at. Some databases auto-populate UPDATE, which means that when you do an update, you can mark a field as auto-change to be NOW as the moment of update. But the way this works, and the way in Postgres it works, is that you cannot do that on a CREATE statement. You use stored procedure, which we're going to talk about in a little bit later. So in this one, both the created_at and updated_at are set to the current moment of the insert, but updates do not alter updated_at, which is counterintuitive and other databases have easier ways to do this. Time stamp with a time zone is the best practice. And it's not so much that all the time stamps have to be in the time zone, although the way I like to do it, is I like to pick the UTC, Universal Time Zone, I don't know when that is. Pick UTC, which is basically Greenwich Mean Time, independent of time zone. So that is the time in Britain. But Britain also has standard daylight time and standard time, and so UTC is always the same. There is no such thing as standard time and daylight savings time for UTC, and that's kind of the difference between, I think, Greenwich Mean Time, British Time, and UTC, even though they are sort of the same time zone. So no matter where we're at in the world, we tend to use the British time zone for time stamps, without daylight savings time. So the idea is, then you can tell Postgres to convert to whatever time zone you want. And this is why, if you've ever taken a plane flight and gone into a different time zone and you bring like Google Calendar up and it says, do you want to see these times in Pacific or do you want to keep seeing them in Eastern? Because you were sitting like me putting all these events in your calendar in Eastern time zone and then they want to show them in the Pacific. And the worst thing, of course, is when you're in a Pacific time zone, and someone sends you email, let's meet at three o'clock in the afternoon. So you go in and you're putting it in Pacific time zone at three o'clock, and then you fly back home and you say, what time is it? Like, oh, wait a second, it's noon, what's wrong with that? So it ultimately in databases because of this whole problem of an online application is working all over the world simultaneously quite often, we do that. But then we can say, look, I want to know what time this was in the local time zone. So for each user, you can give a different view. That's where it says at time zone UTC, EST, or Hawaii Standard Time, or whatever. So there's a whole bunch of time zones. If you look at the earlier versions of Postgres, there were some 14 or so time zones but they realized that's actually not accurate. Just take a look at time zones, you'll be amazed at how complex time zones really are. Not all time zones, and you see even one here, not all time zones are even numbers of hours. This Indian/Cocos is six hours and 30 minutes away, right? And you'll see some that are 15 and 45 minutes and you're like, I'll bet it's tough to live in that area, and set up a multi-person real-time conference and get it right. Because that just means that like your calendar goes off by 30 minutes, right? If you get like a calendar invite from a person in the US Eastern time zone, and your place is going to be on the hour, it's going to be on thr half-hour. So we're actually going to play with this data a little bit later just because it gives us a little bit of data. The abbreviation is the commonly used thing like EST for Eastern Standard Time or BST for British Standard Time. is_dst is whether or not this is daylight savings time or not in this little table. This is a common thing that databases do is they make these sort of pseudo-tables that they realized that they could make a thing called, what_timezones_are available. Or they could just make a fake table that you just use SQL statements to do, and that's cool because now you can do things like a WHERE clause in it, right? So you'd say, well, SQL is a good way to look at data, so let's just make a fake table with this stuff in it. And when you install your Postgres, you might have to pick your time zones or you can add new time zones to it. And so looking at this pg_timezone_names, tells you what's going on in the particular database that you're working in. So this is a good time to talk about casting. I don't know where the word came from. Casting is the idea in programming of taking a variable or a constant that's in one type and converting it to another type. It might be converting from an integer to a string, etc. And so there are several syntactic ways that Postgres does casting. So there's this double colon, which actually I think is a really pretty syntax, that says NOW, and NOW is giving you a TIMESTAMPTZ, a time stamp with time zone, but turn that into a date. So that effectively is truncating that part off, The CAST function. So NOW AS DATE, AS is a keyword, DATE is one of the predefined types. That is a more standard way to do it, and this here is a contraction on that, okay? And then NOW AS TIME just chops off the part that is the time only. Think of this as a type conversion. So we're viewing this through a date lens or we're viewing this through a time lens. We can also do date interval arithmetic. This INTERVAL itself is a keyword, and it takes as as a parameter, a little language like 2 days, 5 hours, and you can go look up what this interval language is, And so this basically a common thing that we want do is like, what was two days ago, right? So this is NOW, and this is NOW minus two days, so you say it was June tenth and it was June eighth, right? And you can also just cast this to a date. So this is the date right up here. This right here, NOW - INTERVAL 2 days :: date is casting two days ago into a date, i.e., throwing away the time part. So we can do various date interval arithmetic. There's also a function that's built in that allows us to it's called truncating. It's allowing us to throw away some of the accuracy that's in a time stamp, like just chop it off at some level. So I want to chop this off at the day, I went chop it off at the hour, at the minute, etc. And so this is a simple thing, it's is a little bit of a complex bit of code, where we're trying to find comments that were done today. And so what we're saying is created_at is greater than or equal to day, which is, if you take the current moment and you truncate it down to only be a day,
Play video starting at :10:54 and follow transcript10:54
and if today is greater than or equal June 10th, and created is less than or equal to day NOW plus one day, but truncated down to be only a day, that would be, this little bit here would be June 11th. Okay? So how did I find this? I think I went to Stack Overflow and I said, how to find things that happened today with a created_at or something like that. So don't feel bad about going to Stack Overflow on this stuff, I'm mostly giving you entry points into Stack Overflow. Now, this is a topic that will be coming up a lot in this class and in the next class, and that is that not all queries that return the same results have the same performance. And it has to do with the fact that sometimes the way you express a query, the way it has to do is retrieve a lot of rows from the database and then look at every single one of those rows. That's the slow way to do it, and we call those things table scans. And so when we start looking at the performance, we can say, "Hey, take a look at this query, how is it going to perform?" And then they'll say, "That thing you did right there is going to cause a full table scan," which means oh crap, we've got to read all the data and use an if statement, like a loop in an if statement, to read all the records. That's the slowest way to do it. And the problem with databases are they're big and the data is spread spread all over, so reading all the records is often has some consequence in terms of performance. And so the question is, is there a way to make it so that I give it a WHERE clause so that it's not reading all the records. A WHERE clause where you don't read all records is where you have like a unique index on a string field, and you say WHERE email equals csev@umich.edu. There could easily be millions and millions of records, but there's an index that lets it go straight to csev@umich.edu. So that's what I mean by, that's not a full table scan, that's like a 1-2 I/Os even for millions of records, okay? And so I'm just bringing this up now because this particular way of doing business, or this particular way of selecting the comments that happened today, you could say, let's take today and truncate it down to today's date, that's converting it to a date. The date of creation is equal to the date of NOW. Now I can't really explain to you at this point, and this could be a fun Stack Overflow thing for you to look up, why this is a slow query, and this is a fast query. I'll just say that at some point, there's like something inside the data that it can take advantage of with DATE_TRUNC that it can't take advantage when you're doing the casting. So it doesn't mean it couldn't in Postgres 14 learn to make this fast, right? That's the thing. Just because there's no rules, there's just the fact that this version of this query is slower than this version of the query, and we'll talk about that more. This particular one, you don't get to control much, you kind of just see that, if you were to do the explaining on this one, you would see all that causes a full table scan, and this one does not cause a full table scan. So I'm bringing that up because this will be sort of a running theme as we talk about some of the queries and say, yeah, this technique is better than this technique because one technique causes a full table scan and the other technique does not. So up next, we're going to talk about DISTINCT and GROUP BY where we're doing something with duplicate values in the columns vertically.

# DISTINCT / GROUP BY

So now we're going to talk about DISTINCT and GROUP BY. In a way, this is another sort of lens in which to look at sort of vertical replication. So we talked about vertical replication. We talked in the second lecture about modeling and removing the vertical replication but not necessarily removing all, remove the string vertical replication and then putting that in a separate table. And that's what we're doing with joins and data modeling, and all that stuff. But like when you join all this stuff back up, the vertical replication reappears sometimes. Or it might even just be that there are numbers that have vertical replication. So sometimes it's the result of a join. Although I'm not going to use joins in this example so you get a better sense of what this DISTINCT ON and GROUP BY are. But the idea is to remove vertical replications as the result of a SELECT statement. So you do the SELECT statement and then you're like, okay, I've looked here and I've got vertical replication, maybe two rows or three rows that are the same. I only want one, so that's what DISTINCT is. DISTINCT is the simplest to understand. DISTINCT ON is if you have more than one column but you really only want to duplicate replication on a subset of the columns so that you don't care, you allow duplicates in some columns and want to remove duplicates in other columns. GROUP BY is really cool in that when it sees this vertical replication and it's throwing and it's sort of reducing from three to one, it's doing something with one of the other columns like it's counting the number of rows or it's finding the maximum of some value in those three rows with identical values in certain columns or taking the sum or average or whatever. So the GROUP BY tends to be combined with what we call an aggregate function which is sort of taking a set of rows, squeezing it down to one row, but then adding or multiplying or adding or summing or averaging or counting across all of these vertical rows. So I got some data here. This data is sort of real data. It is from my race car. So I own a race car. My team's name is Sakai Racing Team, which is the open source learning management system that I work on. And so I don't really own all of these race cars. I actually only own the first four of these race cars. I own a Nissan Stanza and three Dodge Neons of various ages. But I needed more data, so I put some cars that, who knows how many more race cars I'll have to buy? I'm not the one that buys all the race cars. I have a chief mechanic and he's just like, "Oh, I want that too." I'm like, "How about we just make a really simple reliable car so we can have fun racing it and not have to keep working on it?" And he's like, "No, I want to put in roller cams," and I'm like "That'll cause the engine to blow up and then we'll have to work on it." So I have to buy several racing cars, one that makes me happy and the one that keeps my chief mechanic his hobby of fixing broken racing cars. So that's how I have so many Dodge Neons. I have two of the Dodge Neons I sold. I gave the Nissan Stanza to a guy, so I don't have that anymore and I have two Dodge Neons that are actually race-ready and one Dodge Neon that just sits in parts in a garage waiting for my chief mechanic and his buddies to go finish it up. But this lecture is not about racing. This lecture is about vertical replication of data and DISTINCT and GROUP BY. So you see this is not normalized. Remember I said that sort of the whole idea of modeling is to normalize it and we kind of got car models and you could normalize this and that'd be a good exercise is to normalize it. But now think of this as not necessarily a table, because it's a really bad table because there's replication strings. But instead think of this as a result of a join, a couple of tables, and now we've reintroduced the vertical replication. But the DISTINCT and the GROUP BY happens after the join. But I'm just going to make this really simple table, hope that makes sense. So let's start with the simplest, right? Well, talk about the concept of the reducing the results set. So it's like a SELECT happens, does its stuff, including possibly joins, to produce this stuff with the vertical replication in it. Then we're going to do the DISTINCT, take the vertical replication out and create the reduced result set, right? And so that's the idea is you've got right now in this little SELECT you've got four rows but three of the rows are duplicates. When you do the DISTINCT option, it reduces it down to just two rows. So don't give me the same row twice. And so if we were to look at a real query here and we were to say okay, select the DISTINCT model, what that really says, now the key and this is a good time to talk about the SELECT statement. So the SELECT statement often for me doesn't get enough love. The SELECT statement is an important conceptual part of the relational database model. And if you just say SELECT star over and over and over again and then read through all the records and throw away the data you don't need, you're actually kind of throwing away a lot of the power of relational databases. So it's important that you only ask for the records, the columns that you actually need because then that lets the database give you the information you actually need in the most efficient manner. So that's where this DISTINCT. If you have two columns, the DISTINCT does something different than if you have one column because in a sense you're sort of blinding yourself to all the other columns and I want to SELECT DISTINCT and model, and that's different than SELECT DISTINCT make,model, right? So by reducing sort of the horizontal width of your query, that's a critical element of why SELECT works and how SELECT contributes to the efficiency of the SQL statements that we're going to produce. So all we're basically saying is SELECT model, which in effect, by not mentioning these other columns, they're not part of consideration. Because if you did a SELECT DISTINCT ON, well I didn't make this very good over here, I should have changed this data. But if you did a SELECT statement on model,year, then these would all be distinct because the year makes them distinct. Although here's a couple of Mazda Miata 2001s and they would get classed. But I'm only selecting model and price because the SELECT is creating a narrowing of the width of our view that we're taking on this. And there are indeed duplicates as you look down, right? Neon, Neon, Neon. So throws that away, it throws that away, it throws Mustang away. Second, third, and fourth Miata, throws those away. Second Opel GT. Part of these are cars I someday do want to buy, I really would like an Opel GT. But the problem with Opel GTs is if you turn them into race cars, they're kind of classic cars. So what do you do, ruin classic cars. But you've got the idea. So SELECT model, change the width, but then you have duplicates and then DISTINCT simply throws them away. It's a pretty efficient process. This is the DISTINCT ON. And I'll be honest, I'm not sure I've ever used this in my whole career in databases but basically what it's basically saying is that this DISTINCT ON make,model. So if we think about the width of this query, make,model is the width of this query. That's the columns we're interested in which means the others are ignored. And then we're going to do DISTINCT but we're only going to be distinct on the model. We want the model to be unique which means Opel can appear twice. So if you said DISTINCT make,model, then, well actually it's the combination. So it's whatever. It tolerates duplicates in the make, is what that does.
Play video starting at :7:52 and follow transcript7:52
Now, I want to move into GROUP BY and instead of giving you some race car data, I'm going to play with actually the time zone data. I just play with time zone data because it's already there and it's important to know about time zones. And so just think of the time zone data as some data that happens to be in a table that I just didn't have to fill up. Okay, so the simplest of GROUP BY is you basically say GROUP BY abbrev. And this is kind of like DISTINCT ON abbrev or DISTINCT when only you're selecting abbrev. And so in this abbrev column, you're going to see no vertical replication right? So that's the idea. And then that means that if there are two rows that have this as their value for abbrev, then we're going to count them. So we want to count the abbrevs when there are duplicate values for abbrev. How many did you get? I got, there's two that look like this. There's one that looks like that. There's four that are IST, etc. And there's 15 that are plus 05. And so it's a way, like a Python dictionary as it were, where you're finding a thing, you're group bying it, and then you're doing a count of those things. So it's kind of like a Python dictionary. So the GROUP BY is where the vertical duplicates are going to be squeezed out of. But in the process of squeezing out, we're going to count the things that are being squeezed out. And I think you could probably make this COUNT star because star means the whole row and it really is counting the number of rows that you're throwing away. But in my my brain, I'm like, keep the width narrow, don't ask for stuff you don't want. I don't think star really does that, but I just like the idea of expressing the minimum amount of information, asking the database to give you the minimum amount of information that it can give you to make you happy. So the WHERE clause works a little weirdly in the GROUP BY, and so here's a WHERE clause. If you go back and you look, there is this column called is or is not Daylight Savings Time. False, false, false, false. And some of the lines are true. And so I can say I would like to do the thing I just did, that's this part here to here, but put a WHERE clause. So what happens here is this WHERE clause is before the GROUP BY. It has to be before the GROUP BY. If you put the GROUP BY before the WHERE clause, it will yell at you. It'll say you've got to put the WHERE clause before the GROUP BY. So what's happening is the WHERE is filtering the records before the GROUP BY. So that it's just storing all the Daylight Savings Time false values out and then that's a set and then it's doing the counting on that reduced set. So the WHERE reduces the result set before the GROUP BY happens. But that might not be what you want to do. You might want to only see the ones where the count turns out to be more than 10. And so HAVING is like a WHERE clause that happens after the calculation. You could almost call this WHERE_before GROUP BY and WHERE_after GROUP BY. But that's what it is. HAVING is having is just kind of like another way to say WHERE, okay? It really looks the same. The difference is in the HAVING clause, you can put this COUNT abbrev in that HAVING clause, but you can't put it in this WHERE clause and you can't move the WHERE clause after the GROUP BY. So it's just kind of like this. It does this thing, it does the GROUP BY, and then in effect it applies the HAVING to the result of the GROUP BY. Quite nice, quite pretty. Up next, I want to talk about sub-queries or sub-selects. This is another thing that makes your database administrator really upset if you use this feature too much.

# Demonstration: SELECT DISTINCT
Hello, and welcome to another PostgreSQL walkthrough. In this particular walkthrough, we are going to work on DISTINCT and DISTINCT ON. So I'm going to create a table, and I'm going to put some vertical replication in it because DISTINCT is a way of eliminating vertical replication. And so I'll just go ahead and fill this in, create the table, and put that data in with lots of vertical replication for these makes and the models Nissan, Dodge Neon, Dodge Neon, Dodge Neon. So we even have sort of some with nothing but the price and the year change in the three Dodge Neons, etc., etc. So the key idea is SELECT DISTINCT. So let me first say just SELECT make FROM racing.
Play video starting at ::53 and follow transcript0:53
And you see that there's a bunch of vertical replication, right? Dodge, Dodge, Dodge, Ford, Ford, Subaru, Mazda, Mazda. So all you have to do is say, "you know what, I don't want any duplicate rows." So the simplest form of DISTINCT is the most powerful. SELECT DISTINCT make FROM racing. All that says is "don't show me the same row twice", right? And so that sort of just gives you the rows, but only the ones that only once. You can think of it as it's going through the SELECT and it says, "oh this is going to produce a row, is it already there? If it is, don't put it in again." It's as simple as that because it's going through the database finding all the rows that match whatever WHERE clause, etc. And you can say, "I'd like to SELECT DISTINCT make,model." And then that basically does the combination of make and model. SELECT DISTINCT make,model FROM racing, and that's this. So that again it follows this rule of the row, which is the combination of all those fields. Don't give me more than one identical one. So that's basically doing this distinct processing. Now, you can control DISTINCT a little bit more with this DISTINCT ON. And so what the DISTINCT ON does is it basically says, you know, give me these rows. And what I really want is, I'm really most interested in duplicate removal in one of the columns. So I can say SELECT DISTINCT ON (model) make,model,year FROM racing. And so that says I really don't want any vertical replication in the model column, right? So there's no vertical replication in the model column. Now this is a little different than just doing a select of make,model,year year from racing. Okay?
Play video starting at :3:2 and follow transcript3:02
So there's a lot of vertical replication and it eliminated this, but the interesting question is like in these Dodge Neons that have three numbers, which of those three numbers made it in? So we're doing the DISTINCT reduction here on the model that we want, but it really is discarding. So it's creating all these rows, creating all of the make,model,year row combinations. And then it's discarding them because we've asked for a distinct processing on the model field. But do we know which one of the makes it got although there's actually no duplication of makes. But let's look at years for the moment. Which year is going to pick? Well, you can do that by specifying an ORDER BY at the end. And then it will kind of pick the first row that it encountered. So if I say SELECT make,model,year FROM racing ORDER BY year DESC, that says, do that descending by year. So there we got the year descending. So the Dodge Neons where's my Dodge Neon '95, '99, '98, right? Probably what I wanted to see there was I wanted to see by the model m-o-d-e-l, the model, and then the descending. So now it makes more sense. So I see the model's been sorted, but then within the duplicate it sorts them. And then what I can say is I can add to this, I can say, DISTINCT ON, and then I'm going to basically as it's going through model, it'll find the first one. So you'll see that it finds the first one, and discards any duplicates in the model column, but it's because I've ordered by it, right? I've done an ORDER BY, I'm going to get the first one. So if I add to this and say, SELECT DISTINCT ON model,
Play video starting at :5:19 and follow transcript5:19
it's going to go through. It is going to go through these rows. They're going to be ordered by model and year in descending. Then it is basically going to be doing the discarding by looking at this and say, "do I already have one of these models? If I do in this GT case I'm going throw the second one away." Right? So you'll see that it throws everything, it only pulls, in effect, within any group of models because you'll notice that I ordered it by model first and then year descending second. It's going to only pick the first one. So let's see what we get. So we get Mazda Miata 2002 and indeed Mazda Miata 2002 is the first of that set of rows. So I could just not do descending, and you will see that it's going to give us the earliest model of, say, my Dodge Neon 1995. And ff I look at my Dodge Neons, I have '95, '98, and a '99 Dodge Neon. Now, SELECT make,model,year FROM racing. I type too fast. SELECT make, model, and year from racing. So with all that SELECT DISTINCT ON, I would just point out that 90 percent or more of the SELECT DISTINCTs, I don't use DISTINCT ON. I just say something like SELECT DISTINCT
Play video starting at :7: and follow transcript7:00
model FROM racing. So there's usually like one column or sometimes I'm doing it with a bunch of rows where there might be duplicate rows after that. Because the one thing that SELECT does is it reduces the rows. SELECT DISTINCT model FROM racing. There we go. Or you could even look at this. What are all the years? I could say to SELECT DISTINCT year FROM racing, right?
Play video starting at :7:31 and follow transcript7:31
Those are the distinct years. If I don't put DISTINCT in, I should have some duplicates. So they threw way some things. So the whole idea about DISTINCT is that SELECT DISTINCT just basically says, and you can have more than one field in here. It just says don't show me the same row twice. And because the SELECT is reducing the data that it's getting, it actually is the post-reduction row that is the distinct processing is handled by.

# Demonstration: GROUP BY
Welcome to another walkthrough for Postgres. In this one, we are going to talk about GROUP BY and how GROUP BY works. And GROUP BY is related to DISTINCT in that both GROUP BY and DISTINCT in effect create a record set and then post-process that record set. DISTINCT is really simple, it throws things away. And for this one, instead of making yet another little data set that's hard to keep track of, I'm just going to play with the built-in time zones. So there are a whole bunch of time zones. This pg_timezone_names is a table that's sort of a virtual table that all the different time zones that you can do. So it's got a name, abbreviation, the offset from UTC, and whether or not it's Daylight Savings Time or not. So we've already talked about SELECT COUNT star. There's 591 rows in the pg_timezone_names. And we can also use a SELECT DISTINCT, which is something we just got done talking about. Which basically is reducing the vertical replication in the is_dst. So you see there's just either true or false, and so if we just do a SELECT DISTINCT, you'll see that there's two rows that are distinct. There's only a false row and a true row, so the SELECT DISTINCT showed me that. But probably I should just say SELECT is_ist FROM pg _timezone_names LIMIT 20, just for yucks. Now you'll see that if you don't say DISTINCT, oh, what did I do? is_dst, not is_ist. SELECT is_dst FROM pg_timeszone _names LIMIT 20.
Play video starting at :1:47 and follow transcript1:47
Let me type it right, is_dst. There we go. So you see how this vertical replication, right? And DISTINCT just sort of squeezes out that vertical replication. And again, it's looking at the rows. If I had added something to that, if I added something to it, the DISTINCT would not just be is_dst, okay?
Play video starting at :2:17 and follow transcript2:17
We just talked about DISTINCT, so I'm not going to talk about DISTINCT again. So here this SELECT COUNT is_dst. Let's take a look at this particular one. So the idea here is this is pretty much like a DISTINCT on is_dst, but in a sense as the duplicate rows are being thrown away, they're being counted. So SELECT COUNT is_dst and is_dst FROM pg_timezone GROUP BY is_dst. So that basically says this is kind of like a DISTINCT, but it's a grouping. So it groups all of the f-rows together and then all the t-rows together and then counts them and gives them back to us. Okay? So that's the essence of GROUP BY. Now I'll have some more complex examples, but it's really important that you have this basic example understood, right? Take a bunch of rows, group them together by the distinct values of is_dst, and then count them. And that's what this is showing us. But we can do some more things, right? We can do things like, we can do the same thing for the abbreviation. Here's all the abbreviations and the count of the different abbreviations that are being used like EST for Eastern Standard Time. There's a whole bunch of those. So that's another one. Now, you can have a WHERE clause. So let's look at this one. Make this one really wide. There we go. You can have a WHERE clause, GROUP BY abbrev right here. So I can say this. Let me just run that one. So we have a WHERE clause and this WHERE clause affects the things that participate in the count. So it's going to calculate this count, but it's going to do this is_dst equals true, right? Okay. And so that WHERE clause sort of filtered the records before it did the GROUP BY, okay? Now the problem is we might want to filter based on this count, and so that's what the HAVING clause is. So the HAVING clause, the WHERE clause is filter the records, pass them into the GROUP BY process, and then the HAVING clause makes it so that we can do it afterwards. So now we can say WHERE COUNT abbrev. Now the key is as you got to be pretty careful, you can't just put any old thing in HAVING here. It's got to be one of the things in the selected rows.
Play video starting at :4:46 and follow transcript4:46
So there were no that WHERE dst is t, GROUP BY abbrev HAVING COUNT more than 10. I think that if I made that false, I might get more.
Play video starting at :4:59 and follow transcript4:59
Yeah, I got more. So there's not a lot of Daylight Savings Times in there. A lot of false Daylight Savings Times. So you'll see that. But again, the WHERE happens before the GROUP BY, and that's why it's this is the order here, it happened with a WHERE clause, and there's a GROUP BY clause, and then there's a HAVING clause. And just HAVING allows you to sort of post-process the results of the GROUP BY, right? I think it's really quite awesome. I mean, it may seem like a silly thing, but believe me, it would be difficult without it. So here we're just going to count the abbreviations, and look for the ones that are more than 10. And so that shows You could also then, I would like to order this by the count of the abbreviations descending. So we'll do that. Right?
Play video starting at :5:58 and follow transcript5:58
So these are the most common abbreviations now, 43, 38. Right on down. That's quite nice. There's only 12 of them that have more than 10, abbreviations that are used more than 10 times. And so this is a sub-query, and we'll talk about sub-queries coming up next. So I hope this whole SELECT DISTINCT was useful to you. I mean this GROUP BY is useful to you. And then coming up, we're going to talk a little bit about sub-queries.

# Subqueries
So here's something that you can just try. So go have coffee with a really good person in databases and sit down. And basically say to that person, say, I'm kind of a beginner in databases and I just learned this great technique, and for me it really makes databases great. I love sub-queries. They are awesome. I can really express what I want so nice. And then just watch what they say. Probably you'll see that it's like in cartoons where they start to get red and steam will come out of their ears. "Sub-queries, what do you mean?" So let me talk to you about. First I'll tell you what sub-queries are and I'll explain to you why they make database administrators so freaked out and angry. Most because they went to training that said sub-queries are evil. Here's a key though that you got to be careful. If you're doing data mining, certain things that are bad in online systems are not necessarily bad in data mining. because data mining is about convenience, and if it only takes you five seconds instead of one second, that's no big deal. But if you're in an online system and it takes you five seconds versus one second, and there's a million people doing it, that is a big deal. Okay, so basically what is a sub-query? It is really a query within a query that allows you to replace a value or a set of values inside of a query with another SELECT statement. So we go find this account record that has ed in it and we find out that that's 7. And so we can say, go find content from comment where id account = 7. And sort of to do this, unless we used a join, but let's ignore that for the moment. To do this you sort of have to run two queries. You have to do this, then get the results of this, and then feed that in. And so maybe you're writing Python code or something that is running a query, looking at it. Or maybe you're typing it yourself and then you cut and paste that number and put it into the second query, right? So somehow that number 7 moves from the first query, the result of the first query, into the second query. Well wouldn't it be nice if we could just do that all in one statement, and you can. And so you just put this parentheses and then you throw in a SELECT. Now this particular SELECT is selecting to get a number, because there's exactly one row that's going to make it. And it's where account_id equals is expecting a number. And so it's like out comes the 7 and then these two things basically are then equivalent as long as the number is 7. And it turns out that what if there's two things that came back from the SELECT statement. There's actually an "in" here. There's another operator that if this is a set, you can say WHERE account_id in SELECT blah blah blah FROM WHERE blah blah blah. And so this might be 40 of these things come back. And this WHERE clause is smart enough because that's kind of like an array of IDs at that point. And the WHERE clause is smart enough to see if it's in there, right? So this is a very convenient way of expressing a whole bunch of things really. And if performance doesn't matter, sometimes pretty is more important than performant. Although most database administrators will encourage you to find a way to do what you want it to do without using a sub-query and this is the reason why. The reason why is because when you send a query to the database, whatever that query is, and I sort of draw this with my hand and say, here we send this query and the database is like so smart. It knows about all these things and knows where the data is, and it has indexes, and it's doing what's called optimization. And later we'll talk a lot more about performance optimization, but it's able to take the abstract question of please get me this stuff. Sort it this way, order it this way, group it this way, distinct, whatever. But I don't care how you do it. The problem with sub-queries is you're kind of telling the database how to do it. What you're saying is I have two things I want done and you have got to stop, you can optimize this part, and make this really efficient. But then that part has got to produce some output, and that becomes input, and then you can optimize this part, right? And so the database administrators are like, that's two queries. It's as if you did two queries. It's actually better than doing two queries because you don't have to go from your Python code or your web server to the database twice. And so it's actually better than two queries, but it becomes a slower query. And one of the problems database administrators don't like is slow queries in general. So they might say, no, you slow down because you're such a bad designer that you're doing sub-queries. You go ahead and just do the two queries. And I as the database see two more optimizable queries among the thousands and thousands of queries I'm getting per minute, or per hour, or whatever. And so it produces the sort of, stops the optimization analysis from the outside to the inside. But I'll be honest, I mean, that's only, so it has to do everything inside this parentheses before it can start looking at this. And so it it sort of sees this as one optimization, runs this, gets the result, and then sees that as another optimization. And who knows, database is an abstraction. This is just an expression of what we're asking for, and the result could come in any order as long as we got the same result no matter how the database tried to do it. It's just for now databases have chosen to treat that inner select as a select that reads from the database and writes into like a temporary table. And then the outer select kind of reads from the temporary table and then and then all the other tables. So this second select you'd think there's sort of two tables involved. There is this comment table, oops, comment table, and then there is this table created by the inner select. And again, that's what the database administrators don't like is that temporary table that's sort of part and parcel of how these sub-queries are supposed to work. So that's the basics of sub-queries. If I go back to the HAVING clause, and remember the HAVING is kind of the second WHERE clause that happens after the GROUP BY. So the WHERE clause happens before the GROUP BY, then you have the GROUP BY, and then you have the HAVING clause which is a WHERE clause. And so you can only look at this COUNT in the HAVING clause. You can't do it in the WHERE clause because the WHERE clause is what helps produce this COUNT value.
Play video starting at :6:47 and follow transcript6:47
That's from before. Now if we didn't have HAVING, you'd be like oh, that's pretty bad. And I think most databases do have HAVING. This actually is really, once you understand it, I think this is very elegant. But let's just say you didn't have HAVING, you could do this with sub-queries and some unhappiness on the part of your database administrator using this SQL. So the sub-query, remember, is you start with parentheses. So we have kind of an outer select and an inner select. The inner select happens first. And then we're kind of making a temporary table. It's like, stop everything, run the inner select, take those results and put them in a table. And those tables have columns on top of them, right? And so this SELECT COUNT abbrev FROM WHERE GROUP BY, well then that produces a little table. And this temporary table we're going to call zap temporarily. Then from that from that inner table when that work is done, it's going to select count and abbrev, right? Now the count, the reduction, the distinct, the group by, that all happened in the inner query. So it's a rather small table. But now we're going to select count and abbrev from that temporary table with a WHERE clause that says where count is greater than 10. So it's the same thing that's having happening in happen. I mean, happening in HAVING, right, in that it does it and then does another thing. This is a lot cleaner and there's a chance that the database might be able to optimize this because we're doing a better job of expressing what we really want. because here we're kind of expressing procedurally, do this first, make a temporary table, and do the next thing based on reading the temporary table. So we're kind of making it be steps and we're saying do it in order which means it's harder for it to optimize. Whereas this could be optimized, we don't know if it's going to be optimized but by not using a sub-query we have given the database potential to optimize it. And so that's why database administrators would rather you write this line than the sub-query line. Because maybe they can look at this and they can find something inside the database that they can make this go faster. But then they can't do something inside the database to make this go faster. And so that that amazingness that is the database, the database administrator can be part of that amazingness because they can do things like add indexes, change indexes, recreate this or that, or remove data around it. There are things they can do behind the abstraction that make these queries run faster. And a more abstract query like this one has a better chance of being optimized with the help of your database administrator than this one. And so that's kind of why they don't like them. So the next thing we're going to talk about is concurrency. Concurrency really only matters if you're kind of an online system and these transactions, like banking transactions, are coming at the same time. But it's still an important concept in case you're going to run into it. And that's we're going to talk about next.

# Demonstration: Subqueries
Hello and welcome to another SQL walkthrough. In this walkthrough, we are going to talk about sub-queries. And so sub-queries are a powerful and useful technique.
Play video starting at ::13 and follow transcript0:13
People don't like using them in high-performance situations, like for online systems, but we're going to use them a lot for data manipulation, especially the kinds of things that we're just going to do once. Or it's a way to manipulate data that we're not going to do 1,000 times a second. So let's take a quick look at some data. The idea of a sub-query is it takes the results of one query and feeds it into another query. So if we just take a look here. So we get SELECT star. This is pulling out a one row of a record. But if I switch this to be,
Play video starting at ::56 and follow transcript0:56
SELECT content FROM comment WHERE account_id=1, well that is going to find one of the comments for Ed, right? So if you recall earlier when we were hand-constructing some of our many-to-many relationships. We were remembering. So let's actually make this be a SELECT star SELECT star FROM comment WHERE account_id=1, right? And so account_id, we're knowing what these things were, what these post_ids were.
Play video starting at :1:32 and follow transcript1:32
We're figuring all these things out by hand. But we can actually look at this. So we can say, wait a sec, we actually know, we have a way of looking up this number 1. And we can look it up with a WHERE clause here. And so what we're going to say is I'm going to say SELECT id FROM account WHERE email equals ed@unich.edu.
Play video starting at :2:2 and follow transcript2:02
So here we go. This is a way you get at that number. Wouldn't it be nice if we could say we could run this one here
Play video starting at :2:11 and follow transcript2:11
and get this number here instead. And then we could actually look up content from comment where email equals ed@unich.edu. And that's kind of what the simplest of sub-selects are. So what I'm going to do is I'm going to go right here and I'm putting some parentheses, and I'm going to take this SELECT statement and put it in there. So now I have SELECT content FROM comment WHERE account_id equals, and then this SELECT statement. This is why they call them sub-queries or sub-selects because what it does is Postgres runs this SELECT, gets this number, and then runs the outer SELECT. This is both the reason that people love them and the reason that people hate them is that it requires in effect two separate operations which the outer operation is in a sense paused until the inner operation finishes. What we're doing here is almost instantaneous for both of them, but if you're doing this for a long time on things that run over and over and over again, it can be inefficient. But basically it works exactly as you would expect. Now and so the way you work is you work until you get like your query the way you want it that gives you this number, and then you have a query that uses the number, like this SELECT content query. And then you say, oh, I can combine those two things, and so away that I go, right? So that's what the simplest of sub-queries is.
Play video starting at :3:33 and follow transcript3:33
And so that's a very, very simple sub-query and it's very counter-intuitive. Now, there is another version of the sub-query, and let's go back to a previous example where we are using the HAVING clause. Remember the HAVING clause happens after the GROUP BY process. So we have this GROUP BY and then we have in effect the results that come back from that so we can get that GROUP BY to finish, and then we have this HAVING clause, and then we're going to have an ORDER BY. Well, what if you didn't have a HAVING clause? You could use an outer and an inner WHERE clause. So you take. So what we do is this, right? SELECT So let me do this a little differently. Let me change where this line breaks, and then we put this parentheses out here, make this more than one line so you can see a little better. Okay.
Play video starting at :4:28 and follow transcript4:28
So this is a sub-query right here. And this is a query you can run. You can actually run this query and you can see what's going to happen. Oops, I forgot a semicolon. And you see that it's a series of rows. So this is a query that doesn't, like the previous one we just made a single number, this one creates a previous set of rows. So what I can do this, is now I can put this in the FROM clause. So this the FROM clause to this outer query ct abbrev. And then away I go, right? And so I give this AS zap. This AS zap is a way to give this inner temporary table in a sense. This is like it's going to make a table, because this whole parentheses right here is, that's like a table that I just am making temporarily.
Play video starting at :5:17 and follow transcript5:17
I'm running this query, I'm running this query right here. And then I am creating a table that we'll temporarily name zap. And then I'm going to SELECT from that and I'm going to apply a WHERE clause to it, right?
Play video starting at :5:30 and follow transcript5:30
Actually this one would be better done if I made that be a false.
Play video starting at :5:36 and follow transcript5:36
So this shows you a technique that I use a lot and that is I use a text editor to build up my queries and then I pop them over and then I copy them and I paste them in. So, if I don't like it, I can change it. So, there we go, we get a little better count there, right? So, there is 26, 35. We are going to try to make a WHERE clause, but this outer bit, that is going to be the table, quote, unquote, from which this outer clause is going to run. So without further ado, let's do that. So we're going to see and you all as you build these, you'll notice that the output of this query is two columns, and I am treating those. And I can give these things different names because this ct is just the first column of the inner query. And abbrev is just the second column of the inner query. And so but there has to be the same number. If I don't put the same number here, it'll be unhappy. But then what I can do is I can treat this output as a table itself, right? And so that's what's going on. And so if I run this whole thing, you're going to see this with a WHERE clause, right? And the WHERE clause is this outer number, this ct. So this became a table, and that became a WHERE clause. I could even add to this an ORDER BY. But then that ORDER BY ct DESC. So that's going to order by this ct, which is this virtual column here.
Play video starting at :7:17 and follow transcript7:17
So that's going to order by them in descending, so the largest one is going to be first. And so, the sub-query is one of those things that it's really essential. And, again, it's an optimization boundary where we can't make this query go faster. This outer query must completely wait until the inner query is completely finished. And then, it sort of, if this query is big enough, it kind of has to write it all out to disk. And then it has read that query back in. Now, nothing here is large enough that it matters. And it's all instantaneous. But this is why database tuners, especially for online systems, do not like sub-queries. But for us, in more of a data mining context, sometimes sub-queries are essential. And we are typing commands that might run for half a second, but we're only going to type them once and so we're not running an online system. So sub-queries are super powerful and a lot of potential, but we avoid them quite a bit in online systems. Cheers.

# Concurrency and Transactions
So now we're going to talk about concurrency. Concurrency makes the most sense in an online system. And like I said, data mining doesn't always work with an online system, sometimes data mining is working on an online system, but concurrency is an important concept and I just sort of want to bring you up to sort of basic understanding concerning concurrency. If we're teaching sort of an online gaming, how to use databases on online gaming or something, this would be an essential part of it. We'd spend a lot more time with it.
Play video starting at ::36 and follow transcript0:36
So databases in general are designed to be multi-user, right? You got a database back here and you got a thousand simultaneous logged-in users and they're adding 1 or subtracting 1 or updating their bank balance. And it's kind of like database sees this flow of continuous transactions coming in. And the key the database has to solve is atomically. So in this case, we've got, simultaneously, we're going to receive three update statements that are going to set count = count plus 1 for our row number 42. And now all we need to know, we don't necessarily know which one of these is going to go first, but we know that after all three are done, it's got to be 103. And the place that it might not be 103 is what if what it did was the first one retrieved the old value, the second one retrieved the old value, and the third one retrieved the old value, and they would all have 100. They would all add 1 to it and then will store the new value and would all store 101. So you had three attempts to add 1 to it, but the number went from 100 to 101 instead of 103.
Play video starting at :1:43 and follow transcript1:43
So that's the problem. The problem is we don't know which one actually has to go first. But at the end, all three have to happen, which means that the database has to enforce a rule, here comes an update, if there is two updates, they got to go in some order but they can't go at the same time. That's the concurrency bit. They can't be at the same time and that's the atomic bit. So the read and the write of the value count has got to happen atomically before the read and the write of the value count for the next transaction so that's got to be atomic, okay? So the way this really works is there is a locking mechanism inside these databases and the better the database, the better the locking mechanism. because if you're doing a lot of locking in a database, then actually, the lock effort is often greater than the cost of just reading and writing the data. And so when Postgres says, we're really awesome, or Oracle says, we're really awesome, the granularity of the locks and the performance of the locks, and the amount of memory that it takes to do locking as your database size grows, that's like a competitive strategy, competitive advantage to be good at locking. Because this atomicity, the atomness, the ability to do things atomically, is such an essential feature of a relational database. So the pattern is really simple. What you basically do is if you're going to update something, you've got to first lock it, then you can read it, then you can add 1 to it, then you can write the new value, and then you unlock it. And if two things go to the lock at the same time, one gets the lock and the other one has to wait. And then the one that gets the lock gets to completely work and this one is still waiting and then when this one unlocks it, then this one gets to come in, but then they're going to see 102, right? So it's lock, read 100, add 1, store 101, unlock, read 101, right? So that's how you guarantee that if there are three coming at the same time, it goes from a 100 to 103 rather than 100 to 101.
Play video starting at :3:53 and follow transcript3:53
And so each of the SQL statements that we send are atomic and it's not just update statements. Insert statements are also atomic and when we use a serial-type column like id in all these tables that we're building, we're basically saying I want a unique number. You can't have three simultaneous inserts happening say, you know what, you're all key number 1 and the next insert's going to be 4. We do know that we got three records. No, one of these has to be 1 and the next one has to be 2, and the next one has to be 3. We don't know which one gets which, so even when they're insert statements, they somehow have to line up behind each other at least in the id and unique key generation, the primary key generation. They've got to line up behind each other so that they get a unique thing, right? But you can't say who got there first because they arrived at the same time, but the database will force an ordering on them and the next one will be 4. These three will be 1, 2, 3, but in some random order. So because each statement, and when I say a statement, what I really mean is a bunch of stuff that ends in a semicolon, right?
Play video starting at :5:4 and follow transcript5:04
So this is like an INSERT blah, blah, blah, blah, blah, semicolon. So there are things that sort of extend one statement to do two things in one statement, right? So more than one thing in one statement for efficiency and concurrency. So one of the things you can do is you can do an INSERT and then add this little kind of like extra little things that hey, you inserted all those things into the thing including the primary key, which is the id, that you generated, and give it back to me. And then this becomes one atomic statement and your code gets back the numbers, including the automatically assigned id. And the same thing is here. So if you say I want to add 1 to this, set howmuch equals howmuch plus 1 where post_id equals 1 and account_id equals 1.
Play video starting at :5:55 and follow transcript5:55
What value was it afterwards? How many were there? Like you might be clicking a button like this that makes something go up, and then what's the new number? What if two people in two screens are clicking that same button? It shouldn't be 80. It should be 81. So you can basically click this button and it will send add 1 to it and say what's the resulting number and the answer will be oh, 81 because other people were clicking at the exact same time. And so that's what this is saying is add 1 to it and then afterwards give me that record back, the updated record, right? Cool. So that's another taking advantage of this concurrency and the atomic nature of each SQL statement by adding stuff to the same SQL statement.
Play video starting at :6:41 and follow transcript6:41
You can't just keep doing this forever. This RETURNING is a feature that we use and we use a lot. So the next thing that you do is sometimes you make a constraint and with the intention that you're going to bump into the constraint and then tell it what to do when it bumps into the constraint. You can almost think of this as like a try and except in Python where you say like try this. If it works, just great. If it doesn't, do this other thing. So if we inserted a record, this record here, and then we tried to do the insert again, it would actually fail, right? And so sometimes the record exists because because a unique constraint on post_id and account_id because the insert that's already, there that combination of 1,1 is already in the database.
Play video starting at :7:33 and follow transcript7:33
Because of this insert. Now this one here is going to fail. And so it's just going to blow up but it turns out that what you can do is you can say I would like to insert this stuff.
Play video starting at :7:47 and follow transcript7:47
So a lot of my updates turn into inserts and then ON CONFLICT. And so what this is saying is if this insert would fail because of the unique key constraint of post_id and account_id, don't blow up but instead, this is like this is like the try/except, instead, add 1 to the thing that's there. Add 1 to that howmuch value, okay? Set howmuch equals fav.howmuch plus 1. So that's like try and except. This update doesn't trigger unless this is true.
Play video starting at :8:22 and follow transcript8:22
And so this always works and it works whether there's a record in there or not. It works where those record in there or not, and it does a third thing. So it's got an if statement in here. If this insert is not going to work well, then do this instead. And oh, by the way, return the new data whether it was an insert or an update and that includes the new value like the 85 or 90 or whatever. It is after you click this, right? Now, if there's zero here then it's going to insert it and you're going to get 1 back. If there's 79, you're going to insert it. you're ging to update it, its going to be 80. Of if a bunch of people are updating at the same time and you might update and get 85. And it all works and it's all it's all atomic, right? It's all atomic and this is one transaction, one SQL statement, one semicolon. And it's a beautiful thing. And so if you look at my code and you find I'm doing I'm doing a lot of inserts where you think I need to be doing updates. Because it's really it's insert only happens once and then the primary key the the unique constraint clicks and then it just turns into an update, but it's easier than me putting an if statement and making two actual SQL queries because that's costly and that's a waste of time. So I'm not going to go into great detail. I might do a little visual demo of this. This is what we do when we're actually explicitly doing transactions. I haven't done this much mostly because the applications I build are online but not banking but the one time I did it I built a little tiny multi-user game to match people up to play Rock Paper Scissors and then play the Rock Paper Scissors. And the problem I had was when you're starting to play Rock Paper Scissors and you pick your Rock Paper Scissors and you want to play, we have to decide if someone already is halfway into a game and you play them or you start a new game. And so you kind of have to go and you have to check to see if someone's ready to play a game and if they are ready to play a game, then you lock them. And then you play the game and then update them and then one of you wins, right? So there's things where you just have to grab the data. So this is real transactions, right? You're really going to do it. And in particular, it has to do with time passing. And so I want to say SELECT howmuch FROM here WHERE this AND this and then this FOR UPDATE. This is this for, oops. This FOR UPDATE, that basically says lock it. It doesn't lock for people who are just reading it, because they might read it before you change it, they might read it after change it, and because of the asynchrony they kind of don't know. But if there's anyone else that's also locking it for update, if you get here first, then this one will actually wait. So if you select it and no one's done it and you can get both the data and the lock so you get the howmuch value and you have locked it. And if you wait you are now just there's a little wall around that row that you put there so I say FOR UPDATE you put a wall around that row the second one comes and they hit the wall and they simply wait. Now they only wait, you know, 30 seconds or something because these locks are not supposed to last a super long time. They're supposed to be like, you know, just like a millionth of a second and be done with but you can, if you're doing it by hand, be mean and hold a lock for a long time. So you this is where you might do this with two windows. You do a SELECT, hold a lock, and then in the other window you try to select and hold a lock and it just sits. It doesn't even say could not find lock. It just stops and sits. And then what you do is do your stuff and there are one of two ways to end a transaction. One is ROLLBACK. And ROLLBACK basically says I want to whatever I did since I said BEGIN, discard it. Unlock it, unlock everything, and discard it. COMMIT says take what I have done and commit it to the database. So in a sense when I do a rollback, this update doesn't even by the time you get down to here, this update was actually discarded. In a sense what you're doing is you're kind of working on a copy of the row in here and then the rollback says throw away the copy and let go of the lock. Here you're working on a copy of the row, but it's blocked for others so they can't use it. Here you're saying update the real row and let go of the lock, okay? You can read up on this. It's pretty cool. And there's are some I've given you only the very simplest bits of it. As I said earlier, the performance and lock granularity is a feature for a database that says I'm an awesome database because of how I do locks. And so the lock implementation and how we serialize simultaneous access to various parts of our database is a core competency of database systems. So I didn't cover everything. There's some more things like, you know, sometimes you're you're getting a least less strong lock like you're going to update this record including maybe change its key or a NO KEY UPDATE means I'm going to update this record and I'm not going to I'm going to update something in it, but I'm not going to change its key. You can tell what to do when you're waiting for a lock. You can say, you know what, I don't even want to wait. Just select it for update and if I don't get it, tell me I didn't get it and let me do something about it. And SKIP LOCKED is when you are doing a select from multiple rows, which you can do, for update and there might be four rows that would meet your WHERE clause but only three are available because the one of them is locked, you'll get three rows back. So I would like to select something for update. SKIP LOCKED means just give me the rows that are not currently locked and give them all to me if there are none that are locked. And so those are all really cool features. And once you kind of get a little more skill in it, these will make a lot more sense to you. So up next we're going to talk about stored procedures and stored procedures are another way when you have multiple things that you kind of want to do. You kind of store the code in the database server and it runs in the database server versus you writing a bunch of Python say outside the database server and running query after query after query. Some of these multi-step activities can be moved into a stored procedure.

# 	Demonstration: Concurrency and Transactions
Hello and welcome to our SQL walkthrough on concurrency. Now concurrency is not necessarily something that we end up worrying about too much in data mining applications, it's really critical for online applications, but the key idea is that we have things that are happening as a flow of transactions to the database server. So we have many clients, for example, for us we could have one client here, we could have another client here. These are two independent terminals that are connected to the same SQL server and somehow SELECT star FROM fav, and now I'll do that from that one, and I'll say SELECT star FROM fav from this one, somehow the server has to resolve things that might end up with these two different connections, and literally there could be hundreds of simultaneous connections that are doing things. Now, reading is not that big of a deal from a concurrency perspective, it's a matter of fact if two things are reading the same thing, often the database is very clever about that. But if we're starting to add data or delete data or update data, then sometimes the fact that more than one thing is simultaneously trying to do the same thing, that can be a problem. Okay, so let's take a look. So in this fav, just to refresh your memory, the fav is a many-to-many table. So we would be taking a person who is favoriting particular posts and we're going to make it so that they can indicate that they really like something by favoriting it many times. So this is me and this is my post that I like and I'm going to this howmuch is going to be 0, 1, 2, 3 4, 5, and we have updated_at and created_at stuff, right? So the motion that the user's going to go through at some point is hitting a plus one on this, like this is even more of a favorite. And so let's go ahead and run an insert. So the first time if User 1 was going to favorite Post 1, we would set it to be 1, right? And so now if I did a SELECT star FROM fav, there we go. User 1 liked Post 1 this much, right? Now, we only can do that if we know that wasn't done before because if I say INSERT INTO fav again, it complains, duplicate key, which is exactly what we want. We put a duplicate key on the combination of post_id and account_id here on these favs, we take a look, let's go back up to the top here, here's the favs. We basically made a unique constraint on the combination of post_id and account_id on purpose. And then we're going to take advantage of that. But you can't necessarily do the same thing, you can't do the same thing twice because we want to do that. By the way, this RETURNING is basically combining like a select in, so RETURNING star, this is like do the insert, and then do a select. This is like RETURNING is after that insert is done, SELECT star from the table I just inserted into. Now, if there's already a record in here, we know that the thing we want to do is we want to do an update. And we stick a RETURNING star in there, and so we see the post update. And so look, howmuch has become 2. So we UPDATE fav, SET howmuch equals howmuch plus one WHERE post_id equals 1 AND account_id equals 1. RETURNING star, that just as a quick way to tell us what's going on. And so there we go, howmuch is now 2. Now, what's cool about this is this is run in a single transaction. So we know what the value was after we added one to it, which is really quite cool. And so if two things are going on right now, like if I was doing this, two screens were hitting this update at the same time, this is now 3, it went up to 3, so this is my other terminal, and it's updated to 3. So going back to the first table, I say SELECT star FROM favs. Oops, FROM fav.
Play video starting at :4:18 and follow transcript4:18
Remember, they're singular, Chuck, remember they're always singular, right? So the howmuch is 3. So we've got these simultaneous things happening, going on both at the same time in two different clients. Might be two different web servers, two different threads in the same web server, or it might just be two things connected from two terminals. So it turns out that we don't know which of these two things to do. We don't know whether to do an insert or an update. And conveniently, there's this ON CONFLICT capability. So we can say, INSERT INTO fav, ON CONFLICT means if that insert failed because of a conflict of post_id, account_id, you've got to tell which columns are causing the conflict. These are our two unique constraint columns. So ON CONFLICT, DO UPDATE, SET fav equals howmuch plus one, right? So we add one to it. So what we"re doing was really combining this with an automatic if statement. What's really important is then this is wrapped into a single transaction. So you can have many clients sending this a message like this, an SQL like this, at the same time and the database is going to resolve them. One is going to go first and the other is going to go second, okay? So in this case it is going to, let's do our SELECT again, it's now 4. but let's just do DELETE FROM fav, get rid of everything. So we just got rid of everything. So SELECT star FROM fav, there's nothing in there. And now I'm going to run this INSERT statement again. So this time there's nothing in fav, so there is no conflict. So this first half of the statement is actually going to run. So if I SELECT star FROM fav, then it's there. And if I run that same statement again, this time it's going to have a conflict because it's already there because of the uniqueness constraint between post_id and account_id, and so now if you take a look at the SELECT, you'll see it's 2. So this is in effect insert or update, depending on whether or not the record is there. The only time it does an update is when we have a conflict, and that's why we put those UNIQUE constraints in our CREATE statements so that we can then trigger this on purpose. If I didn't put a UNIQUE statement, the insert would keep on working and you would just get more and more rows with duplicate stuff. So we're using the UNIQUE constraint and then we are taking advantage of the UNIQUE constraint here, but even more importantly, this is all done as one transaction. So if this code is run simultaneously somewhere else, they're going to be ordered. One is going to win, they don't hit simultaneously. If they hit simultaneously, then the database will stop, pause one briefly, do the other one, and then the second one will get run. And so that's sort of real simple. So we love to do these kinds of things. We love to do these kinds of things where we use ON CONFLICT. I do it all the time, insert or update. You could add a RETURNING star at this and then you can tell what the value of howmuch was after, so you're like hit the plus button and it should say 4, And then if you did this in a different window, it would say, you just added it to 5. But even then, that's all done in a single transaction. So even if two things happen at the same time, one would get 4 and one would get 5, and so they would know where they are at, okay?
Play video starting at :8:4 and follow transcript8:04
So it's concurrency in that we want this to work and the database server, Postgres puts a transaction around this automatically because it's a single statement, right? It's a single statement in a transaction. Now, sometimes you want to put more than one statement in the transaction, okay? And so there is this SQL statement called BEGIN and then an SQL statement called ROLLBACK, which means give up, and a then statement that says COMMIT, which says actually do it. And so the idea is sometimes we can't do such a cool thing where we can wrap in a single SQL statement, a whole bunch of cool stuff to do two things. Now, if you didn't have this, and of course you do have this, this is a silly example. But I want to basically make it so I can do a SELECT and then an UPDATE later. Who knows why? I mean, I made this really simple so it stays simple. So this SELECT has this special bit and this is effectively grabbing a lock on a row. The lock's scope depends on whether, I mean, I'm telling it I'm going to lock a row, but it might lock more than a row, we don't know how it does it. You're at least locking the row. You don't want to lock this too long because other things can't happen. So it says, I'm going to select this and hold onto it until I tell you to let it go. So let's go ahead and do this. I'll say BEGIN, that's an SQL statement. We're now in the middle of the transaction. SELECT howmuch FROM fav. At this point that row is locked, okay?
Play video starting at :9:55 and follow transcript9:55
Now I can then say, UPDATE, set it to 99. Oops, what did I do wrong?
Play video starting at :10:5 and follow transcript10:05
SET howmuch. UPDATE. Oh, sorry. I have to change this, I got a typo. This is why I like, oops. UPDATE fav. This is going to be wrong too.
Play video starting at :10:21 and follow transcript10:21
So I got a typo there. So I'm going to do this one now. This is why edit these things inside of a text editor and then paste them over.
Play video starting at :10:35 and follow transcript10:35
I wonder if I took too long on this transaction. Let me do it faster. Let's say ROLLBACK, which probably is not going to do anything. Yeah. Okay, let's do it faster. Oops, undo. Do these two really fast. And then I'm going to do this part faster. Yep. It's happy now. Then I'm going to do what's called a ROLLBACK. So what this ROLLBACK does is this ROLLBACK brackets the BEGIN. And rolling back is giving up on the transaction. So what happens here is this UPDATE, I'll have to show you this again in slow motion, slower motion. So I'm going to do this SELECT again, but without the FOR UPDATE. And you'll notice that this number never changed. It changed in the middle of the transaction. So transactions are a group of commands that are either all going to execute or none of them. So it sort of queues them in a way, and locks all this chunks of data. So let me do that again fast enough so I don't time my transaction out because it doesn't like these things. Let me add this SELECT right in here. So I'm going to do this.
Play video starting at :11:54 and follow transcript11:54
Let's clear this all out. I'm going to start a transaction. I'm going to update in the transaction, and then I'm going to select in the transaction, then I'm going to roll back. Let me do all these really quick because that's what would happen if it was an online thing, it would start the transaction, do the update, it selects it, right? And everything between the BEGIN and the ROLLBACK needs to be done quickly. And that's why I pasted them all at the same time. But look what happens now. Because of the rollback, we gave up on the transaction, the transaction was discarded. So during this BEGIN and the ROLLBACK, it was like working on its own little Isolated siloed version of the database. It wasn't the official database. It wasn't the whole database. And so you can go really far down. And this has to do with the fact that sometimes you've got to say you're going to do some banking transaction, that you've got to look up some data, look up another thing, look at another thing, and lock all those things so that other people aren't looking them up. Then you give out the money, and then you've got to update, and then you've got to commit the transaction. Or you try to give the money out and the money giver outer fails, and you've got to roll back the transaction. So sometimes you're doing a bunch of work in the middle of a transaction and you want to give up. Now, if you don't want to give up, you'd say COMMIT. So now, we're going to set this. And we're going to do a BEGIN, we're going to SELECT. Then hopefully, I'll be able to do it fast enough to do a COMMIT. So there we are. We're at 99, but now I'm going to commit the transaction, which means that everything that was in my own version of this database, that's now committed to the real database, so they all went at the same time. So either none of them happened or all of them happened. I could have a whole series of statements that are in effect temporary until I say COMMIT. Now I'm not in a hurry, but now I can say SELECT howmuch FROM fav where it's 99. Okay? Now, I'm going to show you something. We'll get two windows up. I'm not in a transaction in either window.
Play video starting at :14:15 and follow transcript14:15
So I'm going to start a transaction in one window, in this first window, and then I'm going to try to start another transaction in the second window to show you how the one transaction. So I'm just going to do this. I'm in this transaction, and I would try. I'm not going to do the ROLLBACK or the COMMIT, I'm going to start a transaction. I'm going to grab it and lock it with this UPDATE. Then I'm going try to update the locked row. Then I'm going to see how the update went. Right? And then I'm going to commit a rollback. So I'm going to do this in two windows. I'm going to do it in one window and it's going to work just fine. Right? So it's just fine. Now I'm going to go to the other window and I'm going to run this. And notice how this SELECT FOR UPDATE, I can't get my hands on that row. I just can't get my hands on that row. So let me roll this one back. It's still being nice to me. ROLLBACK. Back. It can't roll back fast enough. Okay, I rolled back. And look what happened. This finished. Right? So this was waiting, this statement right here was waiting until I rolled it back. And that's because this statement over here on this terminal locked it until I said ROLLBACK. Right? So what what was going on is the database was insisting that this statement happened. I'm attempting to run this simultaneously, but the database picked an order, and it was whoever got there first, and because I'm doing it slow, this one got there first. But even if they arrived at the same time, it's like a doorway. One goes through the doorway and the other one is paused at the doorway. Now, there is a timeout on this, I don't know if I'll be able to get you to see the timeout. So let's run this again.
Play video starting at :16:16 and follow transcript16:16
Run this again. Let's run this one in this window and now I'm not going to. What happened? You got to roll this one back because I was in a ROLLBACK. I was in a transaction in this one. Okay.
Play video starting at :16:36 and follow transcript16:36
Roll this one back. I got myself all messed up. Too many transactions, all at the same time. ROLLBACK, roolback. Okay, so there we go. So I don't know how long this will time out. I'm going to just let this sit for a bit. Let me clear this all out.
Play video starting at :16:59 and follow transcript16:59
I do not know how long this is going to wait. Sometimes they have timeouts. Okay. So this terminal has a transaction. It's got a BEGIN, SELECT FOR UPDATE, and then it's got to update. It sees its result. Then I am going to go into the other window and I'm going to do this, and you'll notice that it stopped at the SELECT statement because that lock is held. Now we're going to sit and see how long it takes. We're not going to do a ROLLBACK or a COMMIT. We could do a ROLLBACK or a COMMIT in this first one, and then that would unlock the second one. So I don't know how long that's going to take. Okay? So that's the basic idea of transactions. We can use this like INSERT ON CONFLICT. It's a much more common way, if you want to send the database SQL in and have it do everything it wants without having to talk to it twice. So if we're talking, this pgsql application that we're running is a client, and it's sending commands to the database server. And this is great because this is just one command and it allows us to do two things at the same time, right? Do these two things. Here's this data. If it's not there, insert it, if it is there, update it. Okay? And then at the same moment, do a select. So that is really insert, update, and select all in one statement. One round trip between our client and the database server, and we like to minimize those. These, the BEGIN, the SELECT, the UPDATE, the SELECT, the ROLLBACK, the SELECT, these are all separate communications. So explicit transactions are slightly more costly. And I don't know, this doesn't look like it's going to time out. This is what's called a deadlock, and if this sits long enough, it will detect a deadlock. And so I'll just finish this. If you let it sit long enough on yours, you might find it's something about a deadlock. I'll roll back this transaction. Excuse me. I'll roll back that transaction, which will unlock this side, and then I will do another ROLLBACK on this side, to make sure my database is not messed up. So I hope that was interesting. You have to run this with two. You've got to run two terminals, and you've got to run the the pgsql on two terminals. But I hope that you found this a little bit interesting look at concurrency and transactions.

# Stored Procedures

So now we're going to talk about stored procedures. Stored procedures is another one of those topics that you can start a conversation in a coffee shop about stored procedures and people will often have strong opinions. And I'll share my strong opinion with the understanding that it's just an opinion. I tend to avoid stored procedures at all costs. And the reason that I don't like stored procedures is I tend to move from one database to another. Now, you know, if you're working for a company and that company is a Postgres company, then, you know, they're not going to be nearly as opposed to stored procedures. But if you're moving from Oracle to Postgres to MySQL to SQLite and and you start using stored procedures too much, they're generally not portable at all. Even what's possible to be done in stored procedures has slight variations from one database to another. But if you're a company that is a Postgres company and you're building an online system and you have some query that if you did it all kind of run a query, run a query, read the results, run seven more queries, then do this other thing, and you had to do that for like your main screen, that would be so dog slow. It would be so horribly slow that you'd be like, can we please make that main screen be a stored procedure and someone like me be like would be like oh, man, I really don't like stored procedures, but our company's going to go out of business if we don't take these nine SQL statements with some if statements in the middle and just turn them into a stored procedure.
Play video starting at :1:36 and follow transcript1:36
So from a performance thing, they're pretty awesome because they take multi-step processes that are full round trips between an application like pgsql and your database and then do them all in one database transaction. So the fewer SQL trans statements and fewer round trips between your application and the SQL database.
Play video starting at :1:57 and follow transcript1:57
So they're both wonderful and scary. And so I just I don't say I never use them. I just tend to use them kind of in I like to isolate them and have a real strong reason why I'm going to do it, like I said. A strong reason to use a stored procedure is to solve a major performance problem, because they're harder to test and they're not portable and, you know, maybe there's some rule that you can enforce on a CREATE statement like a constraint or a unique key. The one time I wanted to do this, well, the Postgres did it, was a key where this instead of me saying this field has to not be null and this field has to not be null. I wanted to say one of these two fields must not be null but it's okay for either field to be null as long as the other field is not null. And there's no way to express that in a CREATE statement. And the only way to do that is to do a stored procedure.
Play video starting at :2:52 and follow transcript2:52
The way I ultimately did it was I didn't use a stored procedure, I just made sure I never put records in that violated my rule of two nulls, basically. I didn't allow two nulls. Two columns, two nulls, I wasn't allowed to do. So if that's kind of a rule that must be enforced and as we as a develop software developer, I would much rather have been able to enforce that rule in case I as a software developer made a mistake, And when I am told by my database that I write some SQL and I've violated a rule, I'm not like mad at the database. Because it was my rule that I put in there to catch myself and keep myself from making mistakes. We do that a lot when you're writing trying to write really reliable software. You make rules that when you break you get stopped. So you at least find when you're making mistakes. If you well whatever, we'll just let it go, well, then you don't find your mistakes. So that's the whole idea of a stored procedure. That's like double-checking something to say don't be doing this. So I'm going to go back and talk about one stored procedure and it has to do with the updated_at in the updated_at field here in our favorites table. So the updated_at from sort of a semantic perspective is going to capture the moment that this was last modified. So created_at is when it is first inserted, and updated_at. And if you recall, the DEFAULT NOW says at moment of insert pick this current moment in time and store that in the database. And so the problem is that if I want to do this and I have this updated_at, then every time I'm going to do an update statement I can't just do the update of the thing I want to update. I got to say updated_at equals NOW. Now I don't know if you consider that to be like a really terrible task, but other databases actually do this for you automatically. You just have a little different thing that you say right there and you like make just update this every time. Come on, it's this thing I want, right? But you can't do that. You can't indicate on a CREATE statement that you want updated_at to be automatically changed upon update. The right way is to use stored procedure, and it's a super simple stored procedure. And so it's the one stored procedure I'm going to show you. I don't expect you to write a lot of stored procedures, but I just do want you know what they look like. So the way we're doing this is we're going to create a trigger function. What a trigger function is like when something happens, do this. So we're going to make a function. We're going to give that function a name.
Play video starting at :5:18 and follow transcript5:18
And it's going to be called trigger_underscore_set_timestamp. This could be gorp for all we care, that just happens to be a mnemonic name trigger_set_timestamp.
Play video starting at :5:29 and follow transcript5:29
This function we're making is to be used as a trigger in that there are other ways to do it. You can make you can make a trigger. You can make a statement. There are various other things that you can do. You can have a function, a trigger, a statement. But this is a trigger, which is a bit of code that's going to run either before or after some SQL statement's going to run.
Play video starting at :5:48 and follow transcript5:48
So what we're going to do is the BEGIN and END is the actual code of our stored procedure and all we're just saying is whenever we're going to do whenever something happens to this record, that's what the NEW is, we're going to set updated_at to be NOW, and we're done. So we're sort of sort of manipulate. There's a record about to be put into the database and right before we put it in the database we're going to sneak the current time into updated_at so when it goes into the database it's going to be changed. And then this is all just syntax double dollar sign and plpgsql, that's the weird language. Postgres supports more than one language. I don't like stored procedures. But if I do stored procedures, I prefer to use the built-in language. You can use like TCK TK and pearl. None of those things seem appealing to me. plpgsql doesn't appeal to me. But at least it's it's the most powerful of the stored procedure languages, so I just say if I'm living in Postgres land, then be like the Postgresers. And if I'm going to make a stored procedure, do what the Postgres people do because no one really wants to a TCL TK, and it's not going to help you all that much. Right? So this is just like a CREATE TABLE, but it's actually creating a function which is kind of expanding your database like when it creates a function. It makes a little space. I mean it creates a table, it makes a little space for that table somewhere on the disk. Now we're going to stick somewhere a function that can be pulled up and loaded up. The next thing that we do is we actually create the trigger. Now what we're saying is this is kind of like when an update statement happens, i.e., before an update on the table fav, for each row that is about to be updated, run that row through this little trigger. So if there's one row, it's going to come in here and it's going to have its updated_at then it goes back and then if there's a second row it's going to come in. So remember update statements with WHERE clauses could do many rows. So that's why it's for each row this update statement is going to change, execute this trigger, which allows us to here comes the row to the database jump in front of it, tweak it, and then let it continue back into the database. So now when we say set howmuch equals how muchplus 1, implicitly updated_at is set to NOW. And so like I said, stored procedures can be very simple or very complex. I tend to use them for very specific reasons. This seems like to me a good reason because I just don't want to say updated_at equals NOW on every single update statement because I like it.
Play video starting at :8:29 and follow transcript8:29
So up next. I'm going to try to pull a lot of these ideas together and do a demo of reading and parsing files and actually computing primary keys and using sub-selects and making database administrators crazy.

# Demonstration: Stored Procedures
Hello and welcome to another SQL walkthrough. In this walkthrough, we are going to talk about stored procedures. So if you take a look, for example, at our favs slash d plus favs. Sorry, I'm close too. I always keep it singular. I keep my table names singular because it's a place that we keep a fav. So if we take a look here, it's real common to create created_at and updated_at variables in lots of rows. And we can make the default NOW, but that's only when the data is inserted. But sometimes you want to make it so that every time you updated_at is automatically changed every time you change it. So let's go ahead and insert a row. What's in here? SELECT star FROM fav. Let's see what I've got in here. Yeah, I got some stuff. So I got like 999 in there. So I can UPDATE fav, SET howmuch equals howmuch plus one, semicolon, I forgot the semicolon. And so it's up now 1000 and the created date is still the correct created date, but the updated date didn't change. And it's common that we want the updated date to change. Some database systems have a part of the CREATE statement that you can say, auto-update the updated_at. But it turns out that Postgres does not have that feature. So we have to use what's called a stored procedure. And a stored procedure is a bit of code that you can sort of stick in the server that when the server receives its SQL commands, it can add some of your code to all the work that it's going to be doing. It's a way for you to extend the behavior. So Postgres, stored procedures are their own little language and I don't expect you to really write them. I didn't write this one. I Googled like how do you automatically fix the updated_at in Postgres, and I found this. And this is probably the most common thing people do, partly because other databases do this automatically. But Postgres, for some strange reason, doesn't give you a feature to do this automatically. So the first thing we're going to do is create some code. So CREATE OR REPLACE FUNCTION. This is like inserting code into the database. And it's a little weird language, plpgsql. There's a bunch of different languages. I prefer to write them in Postgres native. These things are not portable, they're very unportable. And so you might as well just use the language you are going to use because if you say, I'll use Python or JavaScript, because there's other languages, you find that they have compromises and you're not allowed to do everything in them. So heck with it. Just use that built-in stuff and don't fight about it. So that CREATE FUNCTION put something in the database, okay? It put code in the database. And now we have to associate it. And so we're going to create a trigger. A trigger is this bit of code that like is an event that when it sees something happening, it like triggers our code. So it says, we're going to make a trigger in the table post. Each row that's going to before you update each row, run this code. And this code is basically going to go, here's the new row and before we put this thing in, change the updated_at, and then put it back in the database. So this is like deep, deep, deep in the database. There's no extra transaction. We could put our updated_at over up here on this UPDATE. But this way we are going to make sure every time this data changes, one way or the other, it's going to run. So this basically says go into the post table and mark a little event that says, run my little bit of code right before you finish the update. It's kind of in the middle of the update. The update is started and then we're going to run our trigger and then the update finishes. So between the time the update is sort of handled and the update is actually set in the database. And it's quite simple. And again, I'm not expecting you to write this but I expect you to conceptually understand what's going on here. And you have to realize that this just wrote code, this is associating it with the post table. So you only write the once. I'm going to put it on the post table. I'm going to put it on the fav table, the fav table. And this would be something you'd probably do in your creation statements, and I'm going to put it in the comment table. So now I have these triggers. And so the difference now is when I run this UPDATE statement,
Play video starting at :4:43 and follow transcript4:43
you will see that the update time now changed automatically. So I can do that again and then this update time will change again. The create time doesn't change but the stored procedure has caused that update to happen. So you will find situations where you want to write stored procedures. I tend to generally avoid stored procedures if I can help it, but in this particular situation, it's the way you solve this problem of automatically updating an updated_at column. So it's not outrageous to use a stored procedure in this particular situation. So this is one I want you to know. And you'll run into some problem and they'll say, this way to solve this in Postgres is to use a stored procedure. They're not as bad as you think. Writing them is a skill that only advanced Postgressers, which I don't even count myself as an advanced Postgresser. So I just go find them and then I use them. I understand what it's doing and why it works, but I don't write them as a matter of course. I write a lot of SQL, but not so much stored procedures. Cheers