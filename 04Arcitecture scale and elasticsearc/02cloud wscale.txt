# First Generation Cloud Applications 1/2

So I want to talk about the great disruption that led to in a sense the NoSQL movement and started changing database architectures forever. So prior to this, let's just pick 2002, everybody had their own relational database, everybody bought a $40,000 computer if you had a big school like the University of Michigan. Everybody bought a $40,000 computer and ran your database for your HR on a a $40,000 computer, ran your database for your mail on a $40,000 computer, and just vertically scaled. And it worked, because the software worked in this environment, the hardware worked in this environment. It was not cheap to do it, but it was something we needed to do, and away we go. And so, again, a lot of what I'll call pseudo-cloud vendors used this as their technique, and that is to just make a bunch of databases. They put them all on Amazon and they put the application in front of them and then switched between databases and claimed we're cloud. The answer is no, we just collected all of the individual ones and put them together in one building, or in a couple of buildings in the case of Amazon. So that's 2002. And what happened is Google. So Google's going to search, they're going to write a database crawler and they're going to crawl the web and they're going to make a full copy of the web then they'll index that full copy the web. Then they're going to look at like connections between it. Sounds like a perfect thing for a database because it's all about connections. Just like relational, right? And then of course you have Gmail that comes quick on the heels, right? 2009. And that is here's Gmail. Now Gmail's not just a read-only thing, well, read-mostly thing, but Gmail's read/write. We're going to log in and check our mail all the time and send a message and delete it, and this that and the other thing. And so Gmail is very much like a typical application that would use a relational database, going back to how universities were doing it 2002. But it could not, it just couldn't. Google was not going to give everybody their own domain, even though these days they've changed that but let's go back in 2009. Everybody just used gmail.com. One of the things that was nice about Google was that they really chose applications that didn't exactly need transactions, so that eventual consistency was fine. So think about Gmail, right? You've got 100 million users and they're just logging in but they're kind of logging into their own little data silos, right? And so the eventual consistency wasn't that I'm going to delete a message from your mail, I couldn't do that. I could only delete messages from my own mail. And then I would send and receive mail, but that was just kind of this little email sending thing. And it was all nicely client/server. And so my little corner of the world would send your little corner of the world a message and then a couple seconds later, your corner of the world would see my message and vice versa, then you'd reply. And so, Google worked in these cloud-scale applications and it was a chicken and egg problem in that they wanted to build these really cool scalable cloud-scale applications. And so they couldn't do certain things. Now, you'll notice in the early days of Google, they didn't have charging because then you'd like do you really want an eventual consistency on an accounting system? I don't think so. You want to know I billed them or I didn't bill them, right? Or you want to be able to like if the bill came and you got an email about the bill, you want to be able to log in and see if what the bill was, right? But oh, it's eventual consistency, so the bill's not perfect yet. And even writing to Gmail was widely distributed, right? I mean, like I said, there's just these little pockets of data. In the early days of Gmail they would migrate your data to a server that was closer to you. Like if you went back home to Europe on a Christmas break, the data would sort of creep over to servers that are there and your little island of data would just move around and then all of a sudden be really fast. So there was this data migration. Your little silo of data might follow you around the world as you traveled. And so the early Google applications were not Facebook, they were not Twitter, they were not connection-oriented. They were just like here's a thing for you and whatever. And so these systems used cleverly named files, they used hashing, right? You can hash an email address and that could be like a folder that has a bunch of files in it. Then you'd take the folder names and you'd hash them and then you'd basically make it so that when you delete a file, it just rewrites that folder a little bit, right? And they even could use a little bits of relational database if they felt like it. Something like SQLite, which really reads and writes one file on disk. It's not great for multi-reader / multi-writer, but if there is one database for each user, then SQLite could be a good little database, right? So sharding is the idea of slicing a problem across a bunch of servers and then you sort of have your particular view. It's not like a read replica where you could go to any of them. No, you had your email address and your data was on this one server, that's your shard. And so you've been sharded. So your data is not on all the servers. It's just on this one and unlike the stuff I showed you before, there's only one. That's a shard. And so I want you to watch a couple of videos. You can either watch these on YouTube. This is an hour-long keynote. I've got a much shorter version of it that you can watch. This is Marissa Mayer, Google I/O 2008. I was actually in the audience when she was giving this talk and I will tell you that my mind was blown when she was talking. I go to a lot of conferences and I'm always sitting with my laptop in the conference and I'm like, get some code done, yeah, whatever, they're going to say dumb things, right? I mean, I'm enjoying it and I'll clap once in a while, look, and I'll go back to coding. As she hit this part of the speech that I've cut out, my jaw just dropped and I'm like. And you're going to watch it here in 2020 or later and you'll be like, why was that so amazing and the answer was that in 2008 Google prior to this. This is the first Google I/O conference. It's the Google developer conference,
Play video starting at :6:18 and follow transcript6:18
which I encourage you to go to. They're kind of repetitive after you've gone to one or two of them. I went only to two of them and stopped going because they're so repetitive. Google from a developer perspective just is crap. They just come up with an idea and then they throw it away just like two years later. So Google is really not stable enough for me to like as a developer. I like Amazon, I like Microsoft if you're kind of into that closed-source kind of thing, but Google is just, someday I'll just go be president of Google and just slap those people. I'm like, quit it, quit it. Sorry, sorry, sorry. Marissa Mayer. Great keynote. Google I/O was like opening the covers to what had been for almost a decade at that point completely the most secretive way of building fast systems. And I walked in thinking as a high performance computing person that thought that a million-dollar computer was the way to solve most problems. And what she showed with this gather/scatter technique and this is like, oh, no, she has a bunch of thousand-dollar computers and they go so much faster than my $1 million computer and she can add as many thousand-dollar computers as she wants and I'm like, yeah, that's pretty dang cool. So this, it was revolutionary. And so please watch it. Put your mind in the sense that this was to me the first time that Google was showing how it was able to do search cost-effectively and not charge you for it. Because if I'd have built search in 1997-98 I'd have built it out of really expense hardware and Google did not build it out of really expensive hardware. A year later, they started showing some of their actual techniques for how they build virtualize hardware, and this is amazing. Again, before this time I would see rumors about Google's, this is how Google does it, it was a big secret, right? And what happened was is and and in 2000, it was a big secret. By 2009 what people realized was that with the energy crisis and all these concerns about the footprint of the energy cost of these systems and the fact that they would throw these things away after one or two years. And so everybody, Google and Facebook and Twitter and Amazon, they realized that for the greater good they ought to share some of their best practices on how to do all these things efficiently. And so, they started having Summits . And so again, when I first saw this I'm like, jaw drop. I'm like, that's their secret. Holy mackerel, I can't believe it, it's amazing. I would have never thought of it, that is not how I would have built Google, not me, that's not how I would build it. But then you watch and you go like, of course, it's a wholly good idea, right? And again, ACID and BASE are the essence of this and I was an ACID kind of guy, right? And I was looking at this BASE world, I'm like, dang, that's really cool. And then I also want you to see, so you see this is 2010. So you see Google's kind of opening up their secrets to the world. How did even search work? So this is a Matt Cutts, March 2010. It's a beautifully done production with animation, but it's also think of it from a ACID versus BASE perspective of how they can use a distributed set of computers to go through the web, to pull the web down, to index the web, and then to run searches. So I really want you to watch these three videos. You can either watch the short versions that I've provided, or you can watch the long ones. The Marissa Meyer is the only one where the long one is an hour and my short one is like three minutes. And so, you've got to catch the part where she talks about how to do searching but the Matt Cutts one and the Google container tour, those, if you watch the long one, they're not that much longer than my succinct versions of them. So please watch those and then come back and we'll talk a little bit more.

# First Generation Cloud Applications 2/2
So welcome back from watching my three Google videos. I hope that you found them interesting and they didn't take too much time. So let's talk a little bit about the conclusions that I took away from each of these videos. So if we look at the Marissa Mayer video, the conclusion that I took away was first off Google search, we kind of ascribe Google search to being an "intelligent" life form, as it were. And if Google search takes a tenth of a second, versus a thousandth of a second, we have no difference in our perception. And so the fact that in early 2000s it probably took a quarter of a second or half a second, it's faster now. But if it took a half a second to bring back what seemingly were intelligent results, that was good enough. And so this is another sort of, that's not so much eventual consistency but more just distributed computing. And the idea of the scatter and then the gather, that is a costly way of solving a problem. But if it's the only way to solve a problem, and the problem is tolerant of a quarter of a second latency, we're great. So that was the first thing, and that is that it's not always about how fast. The second thing is if even though that's a quarter of a second, it's not like those resources were all busy for that quarter of a second. So it might take a quarter of a second to go through that network of systems and then come back to you. At the same time, it's only 1,000th or a 100,000th of a resources and there could be several thousand transactions that are in flight being scattered and gathered at the same time. And so it wasn't like it takes a quarter of a second and this computer is busy the whole quarter of a second. It was just kind of [NOISE] the stuff is just going like a giant hurricane flowing through. There's controller things. They send them out. They bring them all back. And so it's not like the quarter of second is a slow problem. It's the gathering and the scattering. But each operation was really, really, really tiny, and it wouldn't surprise me if there was relational databases sitting off and on all those servers for some of the aspects. Whether it's the crawling or the indexing or the searching, there could be places for little tiny isolated relational databases in that entire architecture. And, of course, as the web got bigger or as Google's copy of the web got bigger, you, instead of sending it to 200 servers, you send it to 300 servers. And whatever, you just shard the entire web over 300 servers. And if your search volume got too high, you make more sets of 300 servers, or you just make it 600 servers. And so what was really cool was the scalability of this, that it could stay consistently a quarter of a second no matter how much we started using it, right? And then the container tour. Again, I just figured there would be racks and there would be fancy equipment, but there's not. And part of this is a sense of waste. Why package all that? Here's the thing where it's just kind of on a piece of stuff, you plug some things in, because it's really just a computer and a couple of disk drives and a power supply. And they even have on-board really tiny batteries so that that if there was some kind of a power glitch these things keep on going. They don't even have a big, they might have a big power glitch thing for cooling and stuff if they've got to run their cooling on diesel or whatever it is. But in general, each one of these little little boxes, they can probably tolerate a two-minute outage, right? And then routers have their own batteries. And so it's these tough little independent things. There's nothing fancy about them, there's no wasted packaging. There's no beautiful colored plastic or lights. If there's lights, there's just lights. There's not like lights with a cool. So there was an eye to not wasting energy. And if you watched the whole thing, there's a lot more about energy management in this. There's an eye to these computers are just disposable. I mean, some of them get old, although they use them, they think a lot, if you read other things about this, they think about the lifecycles of how you can take older computers and use them for different tasks etc., etc., etc. And so I found this really exciting. And the other thing is, as you look at this, now start thinking about the Gmail application. And if you look at this guy's shirt, I think he was part of the Gmail rollout. And Marissa Mayer, by the way, was the UI expert on Gmail. So I think that's her biggest claim to fame inside of Google is her work on Gmail. And so in Gmail, you've got these little boxes, right? And you can imagine, I mean, when's the last time you lost data on Gmail? They have somewhere between seven and ten copies of your mail distributed within a rack, distributed within a container, across containers, and that's one data center. Distributed across data centers, and distributed geographically around the world. And so part of the way Google backs up your data, is they don't have a data backup. They just replicate it, right? They replicate your Gmail seven to ten places and eventually that's enough. And so you can lose a whole data center and you shouldn't lose Gmail, right? You can lose a whole container and you should not lose your Gmail, right? And so that's the other thing is the replication. And if you look at the architecture of these data centers, disk drives were cheap. They tended to do the high-performance things on only one part of the disk drive to keep the heads from moving back and forth. But then the backup copies of your email could be on the rest of the disk drive. And you can read up on this as well. They would only use the first ten percent for critical stuff that needed to be performant, and then they would use the rest of the disk to back up other disks. And so it's just like a beautiful thing. And eventual consistency is the essence of it all. So you update your data in your email, and there's like nine other copies of it and you delete a message and then those eight copies are out of date. But four or five seconds later, all eight copies have the exact thing, or in comes a message and it's the one you're talking to. You see the message immediately and a couple seconds later then all the copies have it. So if that copy went down, you might like lose one email message, right? And so it's just amazing the simplicity of the unit of computation that Google did. And now we have Matt Cutts and what I liked about Matt Cutts is how something that if you didn't know how it was done, like how to compute page rank across billions of web pages. You're like, oh, wait a second, you just distribute it. And at night when all the people in America are maybe asleep and not doing searches, you've got all those CPUs and you just run through and recompute the page rank. The PageRank algorithm is designed to be a distributed algorithm, it's designed to converge. New pages show up and they kind of disturb the force for a while, and then they recompute it, and how that page ranking is done. And after a while you realize, well, if you're smart enough, something as complex as Google search is somewhat simple and beautiful and elegant. And so this is sort of the transition from a company that bases its whole life blood on not relational databases. Or, if it's using relational databases, it's using a lot of little ones rather than one large relational database. Now the other factor in sort of this move to NoSQL and the move to distribute it and the move to eventual consistency was Amazon. And at the same time as Google was sort of being formed, Amazon was a book company. But of course, what they figured out was is they had to build server farms so that they could support their books. And they built things like DynamoDB so that their ordering system would be fast and run at scale. So they just built a really cool distributed database so that their ordering system would scale. But then they realized, oh, wow, that's a pretty cool distributed database. But the thing that Amazon did that probably changed the world the most is Amazon Web Services. So you think about the state of technology when everybody wanted to use cheap hardware and Amazon wanted to add virtualization on top of that hardware. And so you didn't want to buy a bunch of $40,000 computers and do virtualization there, which is what we were doing kind of in the private sector. What they wanted to do is do virtualization on commodity hardware, which is dirt cheap, right? But the problem then is how can Amazon give you a ten-CPU box because if they bought that ten-CPU box, people could lease it, let it go, lease it, let it go, lease it, let it go. And they're stuck with a $40,000 capital cost, right? And so it turned out in the early days disks were much larger than their performance, meaning they stored a lot of data, but you couldn't get it at it very fast. And in terms of virtualization, you had CPUs that were very quick, but the thing that was expensive was the memory. And so if you had like an eight-gig computer back then and you were going to break it into a couple of two-gig computers and virtualization, that was really quite costly. And so what they really wanted, the thing that was cheap was smaller computers. The CPUs were cheap, the volume of disk cheap, speed of disk was expensive, and the memory was expensive. So your move toward you get lots of slow disks, not very much memory, and CPU is basically free. Volume of disk is free, CPU speed is free, memory is expensive, disk transfer is expensive. And that's what you could buy. And so you think, well, that's what I can buy, and if I ask for anything else from Amazon, they're going to charge me hardcore. They're going to supercharge me, right? So we started thinking as application developers, we're either going to buy these $40,000 boxes that go obsolete every two years, and another 40,000 or 100,000 or 250,000. These could be very expensive boxes. Could we just rent for 10 bucks a month 10 of those for 100 bucks a month and it's way less expensive, but we've got to completely re-architect our application because we can't use large amounts of memory. And we can't expect that our disks are fast, but we can have a lot of disks. Now if we can figure out a way to build our application to fit in that particular mold, then it's awesome. So these are what we call carpet clusters, right? And so this is sort of a visual metaphor for what Google looked like, what Amazon looked like. And the key is it's buying commodity hardware that is written at scale for all of us to have a desktop computer and then that desktop computer drives, the price of that hardware is driven way down. So you just buy a bunch of these things. And so the extent to which that you can use a network plus a bunch of commodity computers to make what we called a carpet cluster, if you could build an application that could work in that environment, it was gold. And so how do you use carpet clusters, right? Well, you spread your data out, replicate it, send queries broadly, bring it back across the network. Like MapReduce is another word for this. And it might take a little while, but you can have a whole bunch of them simultaneously in flight because it's not the CPU while you're in a system. It's the moving the data into the system and getting the data back out. And that can be done many ways in parallel. So you could create sort of like these database creatures with 128 computers and 128 disk drives and you could send them queries. And there was databases like Teradata, for example, that created that architecture and then put it all behind a black box and let you just send inquiries to it and they go [SOUND], send them out and in. Yeah, and you could just make it be a sharded database. I don't even know what Teradata was. But I wouldn't be surprised if it was just a bunch of little clusters with a bunch of just little tiny SQLites inside of them because SQLite is so super scorchingly fast and reads to disk really fast, makes good use of memory. But it's not good at multi-reader and multi-writer, so you want most of this layer outside of it that makes it look like it's multi-reader/multi-writer but really it's sharding. You're sharding the queries across all these systems. I never built one of these things. I was more into compute at that point than I was into database. But just imagine how much fun it would be to build a carpet cluster database system today. And so now we'll talk about second generation cloud applications. And the key to the first generation was data was in silos. You could have lots of silos, which meant just plain sharding and sending your data back and not having your data talk to other people's data was good enough. And so in the second generation of cloud systems, we can't depend on that simplicity. We can't simplify that much. And so that's what we'll talk about next.

# Second Generation Cloud Applications

So now I want to talk about the second generation of cloud-scale applications. Gmail and Google search were kind of the first generation. The second generation would be like Facebook and Twitter. They have a more challenging problem and that is we weren't all looking at our own little corner of the world with very simple interactions between people. Again, Gmail, we've got our little silo of mail when you want to send a message or get a message, but most of the time we're like reading and deleting our own messages, or indexing, or searching, or whatever, and we have some little corner and we find our way to that corner of the cloud and then we work in that corner. But in Facebook, you had friends. You've got to know who your friends are, you have to add, you have to have a way to manage them, you have to find them, you've got to approve them, etc., etc., etc. There's very complex privacy rules once you sort of start doing social media. And if you go into Facebook and you go search, you're not searching all of Facebook, there's not one search the way there is Google one search, you're searching your view of the world. And so now you've got to create like a search index for every single person so that you can type that. And so we are going to shard it, we're going to replicate it, you just can't use a database RDMS, you can't use a single database instance for this. So the idea is now we're going to shard it the way we do for Google, and you've got your little corner, but what we're going to do is we're going to find ways to get the data to migrate to you. And so if you're Facebook, you want to make it so that when you log in, the thing you see can be shown to you efficiently without going to 1,000 servers. It's not like Google going to 1,000 servers of search, you're going to one server and you're saying, what's new? What's my status? What's my timeline? What pictures came up? And so what they want to do is they want to move that data to the shard that you're at, right? And so the idea is then now you post a status update. And so this is kind of the first picture of sharding that I've given you. And just imagine that you're building Facebook for the first time and you could even be reusing relational databases and you say, look, okay, we're going to do four servers and everyone whose name starts A through F goes to one server, G through M goes to another server, N through R goes to another server, and S through Z, and maybe there's databases but those databases themselves do not communicate. The application is now responsible for moving data back and forth. And so Annie's got some friends, Greg and Sarah, and there's a status. Annie can log in right now and see, whoa, here's your friends. Greg just talked about pizza. And Ron can log in to Ron's server and Ron sees all of his status, and Sarah sees her status, right, and Greg. And so the friends are not in one place, the friend list is all over the place, and there might be privacy configuration, etc., etc., etc. And so let's just say for example something as simple as Annie logs in and gives a thumbs up to Greg's pizza comment. Now, certainly we've have got to send that thumbs up fact to Greg's server. So Sarah is also Annie's friend, so I guess do we send the thumbs up to Sarah or is Sarah a friend of Greg? Oh wait a second, we probably should have sent that to Ron, I think, because Ron actually is also a friend of Greg, but has Ron blocked Greg?
Play video starting at :3:39 and follow transcript3:39
So you see the problem, right? So you see the problem. There's privacy rules, there's whatever, and we want to get back to the point where when any of these four people log in, they don't have to go to the other servers to pull in the fact that Annie has done a thumbs up on Greg's post. So at some point, you've got to get this fact that Annie did a thumbs up on Greg's pizza comment to the right places so that when everyone logs in, they don't have to talk to any other servers to see that in effect their status line and how many likes and how many dislikes. So this is really dependent on lots of things and you say, well, if Sarah is a friend of Annie and Annie liked Greg's pizza comment, does that mean that we also have to send Greg's pizza comment to Sarah and the thumbs up? And Ron is friends with Greg but not friends with Annie and Greg made the pizza status update and Annie did a thumbs up. Does Ron see the thumbs up? Certainly he has to see Greg's comment, because they're friends. This is hard, Facebook's hard. And this is why the privacy options in Facebook are so complex because I just gave you the simplest example and my head has already like got question marks all over the screen, okay? But this really isn't about Facebook. This is about eventual consistency databases and Facebook as an example of eventual consistent databases. So there are engineers who are going to try to make this sort of push to the edge, and I've built some of these applications of what I'll call push to the edge. It's all sharded and you just have to migrate the data, replicate the data, so that the cost to show you a timeline or a timeline update is as cheap as possible. The cost of moving it to ten different servers, because that's how to get to all your friends, is cheaper than when you log in to talk to those ten servers. To say oh, my friends are on ten servers, let me pull their thumbs up. No, no, thumbs up has got to be there before you log in. And so this is very much eventual consistency because you literally could do a thumbs up and it might take 5 to 10 minutes before everyone sees it. Now, Facebook works really hard to get that latency down, but Facebook is absolutely an eventual consistency. And you'll notice things like let's make a friend conveniently are done in sort of a two phase where like send a note to try to be a friend and then the person accepts the friend. And so it's all kind of slowed down so that an eventual consistency database can work. So you can imagine that the Facebook engineers are like just every morning they're solving a new problem of how to do this fast, and how to move it fast, and how to figure out the privacy, and how to get everything to the right place that it needs to be within, say, two seconds or something. And you're like this is the biggest data center in the world. We're talking worldwide, right? And there's going to be some central control, things like who paid for what ad or something. And there might even be some combination of databases. Just using a database that's not like an application-wide database is like a common technique. It's not a problem as long as it's just one database on one server and it's all sharded. That's not it. Because the whole view of it is the base view or the eventual consistency. So this is a comic strip from xkcd. And it basically explains what happens to engineers. And the person on the left says, "Can you pass the salt?"
Play video starting at :7:20 and follow transcript7:20
And the person on the left is waiting for the salt and the person on the left says, "I said." And the person on the right says, "I know, I'm developing a system to pass you arbitrary condiments." And the person says, "It's been 20 minutes." And the person on the right says, "It'll save time in the long run." And that is that lots of engineers when they solve a problem overgeneralize to say, "I've built this thing for Facebook and it's cool. And look how easy it is for me in Facebook to solve this problem of friend lists." And then you solve it, and it's cool, and it runs really fast. And then you say, "I wonder if other people could use this exact same solution." And then you say, "I have a new form of a database." So now we'll talk about the emergence of BASE-style databases, non-ACID databases, that came out of successful experiments in these second-generation cloud companies.

# The Emergence of BASE Solutions (i.e. NoSQL)
So now we're going to talk about how some of these early cloud experiments turned into the NoSQL movement. So the BASE-style database is you've got a fast network, you distribute it as wide as possible, you don't have any central locks, you have lots of fast, low-memory CPUs, lots of disk drives, not necessarily per CPU, but lots of disk drives because you have lots of CPUs. You basically use data sharding, and the indexes are more about figuring where things are at. You end up with documents, not rows and columns. Things like the friend list is just a document that they're friends, right? And another thing you do is instead of like coming up with a schema of exactly what your application wants to do that has rows and columns in one database, you're just like it's kind of a document and there's some key-value pairs. And if like on a Tuesday, I want to add another key-value pair, you've got a kind of nice migration. You just add another column. It's as if you had a schema but you could change it any time by just inserting into a column that didn't exist. And then they're all text, right? And the way to think about this is it's schema-on-read. You just write the document, and then you can read the document and look for values that you expect to be key-value pairs that you expect to be there. And so that's kind of like this next-generation NoSQL, no schema. But there is a schema, as we'll see when we play with these kinds of things. We'll see that there are schemas, but they're kind of late schemas, they're not early schemas. When we're doing ACID, we must have the schema from the beginning, and you've got to be real careful as you evolve it. Another trend that was happening during this time is JSON. And we talked about JSON. JSON is really awesome. It's a great way to just represent key-value pairs. It just is wonderful. There's fast parsers in every language. And again, I've never built one, but just imagine how awesome you could compress JSON if you really wanted to. And one thing about database is that it loves to do is squeeze stuff into less memory, so you can cache more and everything. And so just imagine the keys of JSON becoming just numbers. It's really cool. Compress it, save storage, save data transfer, everything. Just awesome. JSON is a cool format. It seems simple in the beginning, but then you realize that JSON has touched everything, and it's really a beautiful thing. So in this time frame, a series of open source NoSQL databases started to come out. A thing called CouchDB, which was funny. A cluster of unreliable commodity hardware, which is exactly what I was talking about, right? MongoDB also came out along with the Node system, which had the JSON storage. As we moved more of the application into JavaScript and started using Ajax and JSON, and even then micro-services, the MongoDB was really very much part of that movement. Cassandra is the Facebook engineers who figured out how they built Facebook, and they built some open source like Facebook-like capabilities, like Apache Hadoop. These are open source solutions in this NoSQL space. And then Elasticsearch. And Elasticsearch came from really trying to replicate Google search. It's less trying to be a database. Although in later years, folks are like, "I can use this as a NoSQL database, and its indexing ability is superior." So we're using indexing technology because in a way, a lot of NoSQL databases are a relatively simplistic document store layered with a really powerful searching capability and inverse index. And all the stuff we've talked about, except just specialize on that, Like, there is no regular index, there's only inverted indexes. And we're going to do that really well. And now you're kind of like Google, right? Google search is just a really awesome inverted index. But all the engineering in Google is not how to store the documents, it's how to build, maintain, understand, and make good use in a scalable way of the inverted index. So there's a whole bunch of these NoSQLs that come out. There's also a bunch of Software as a Service, and this is a really interesting trend that, in a sense, you use DynamoDB that comes from Amazon. We don't even know how it works. It is the stuff that Amazon uses for itself, so they're eating their own dog food as it were. But what's cool is instead of you having to install MongoDB and hire a person making a $150,000 to run your MongoDB cluster, you just use DynamoDB and pay $10,000 a month for the amount of bandwidth you're pulling in and out of your DynamoDB. It seems expensive to pay $10,000 a month for a database, but if the option is to pay $150,000 for a software developer, and frankly, you need two or three of them if you're really going to be serious about it, and that's going to be a half a million dollars to have enough software developers to really run Mongo well, Amazon starts to look like a super bargain. Google has BigTable. I used BigTable when I used App Engine. I've actually used DynamoDB, found it a little bit slow, so I just use ElastiCache instead. I used it, and I stopped using it. Google BigTable, I used that. I went through a heavy App Engine phase in 2008 and 2009 and wrote a book on Google App Engine. I used BigTable. You could see how BigTable could be used to build a Gmail-like application or to build a web crawler, but not necessarily any other applications. And I kind of had my time with BigTable and kind of walked away from it. I was frustrated with Google's and Amazon, frankly, with DynamoDB. I could not do performance analysis because it was too magical. Now that doesn't mean you shouldn't do it. And I know plenty of people that have good experience with DynamoDB. I don't know so many people that use BigTable heavily. And Azure, Microsoft is always catching up, always catching up. But that doesn't mean that Microsoft is bad, it just means they're catching up. One advantage of coming late to the party is that you know what everybody else did, you can look at the open source stuff, and you can save yourself a lot of time. So of course Facebook is jillions of dollars, right? And so every startup decided that the way to make money was to build a single cloud-scale, truly second-generation cloud-scale application, and just make money. Because that was what Facebook did and YouTube did and Google did, and I want to be like them. And so there's a number of trends that were happening during this time. The emergence of client-side applications, which are JavaScript, Backbone, Angular, React, and Vue. Just each one is sexy for two to three years and then there's a new one that comes out and breaks all that stuff, and they go like, "Oh, that thing that was cool last year is not cool. This is my cool thing now." Which is cool, it's evolving. Frankly, I think there's a technology that's going to wipe them all out called web components. I hope to see that one of these days that we don't talk about those anymore, and we just use the browser-based web components. But that's a slow process, to take all the cool stuff of Backbone, Angular, React, and Vue, and sneak it into the browser itself. Also, the emergence of Node.js, which is JavaScript in the server, which allowed people to learn the JavaScript in the client, and JavaScript in the server, and certainly the JSON exchange and Ajax was all happening. And then you just picked a NoSQL database like MongoDB and Node, and away you go. And these startups, they don't know any better. They are starting, they have no customers, and they write code really fast. And a thousand people use it and it runs fast. And then they find that when they get to 100,000, it all falls over. And so that's the problem. So in 2012, if we look at the Gartner Hype Cycle, we saw that NoSQL databases were in the technology trigger, which means they're all talked about, talked about, talked about, moving up to the peak of inflated expectations and things go kind of from ooh, that's cool to we believe it solves all the problems in the world to like it doesn't solve any problem, and then things get better. So this is 2012, the time frame that I'm talking about. And so what happened, actually sometime like I think 2016, is they stopped mentioning NoSQL databases because it really doesn't mean anything. So NoSQL databases, which is how I kind of started all this, it doesn't mean anything. BASE-style databases does mean something, meaning the eventual consistency databases. So if you look at the Data Management Hype Cycle, you see a whole thing set of things that are like the progeny of NoSQL, like SQL interfaces to Hadoop, document store databases. SQL interfaces to object stores. So the whole notion that there was going to be this NoSQL revolution and SQL was going to go away, that's kind of been replaced by these cool non-ACID databases are cool for certain kinds of applications. And so that we talk a little bit about the start of the NoSQL movement and the end or the maturation of the sort of a true adoption of the NoSQL techniques. So I had a friend who founded a company and build it up and then eventually sold the company called BareSite. And they had a problem. They were going to expect about 100 terabytes of information because it was a cheat checker that would read papers and see if they were borrowing from Wikipedia or whatever. It was going to be cloud, it was going to be multi-tenant, it was going to be single instance, really a second-generation cloud. They started out with MySQL, like everybody does, as a proof of concept, but they did not want to then build so much skill in how to shard. And so they grabbed an open source NoSQL database, Cassandra, and they leased a bunch of hardware, they went because they knew they had to play with the disk drives and play with the memory.
Play video starting at :9:59 and follow transcript9:59
And it worked great until it didn't. And then they had to bring in somebody who was a Cassandra expert, and that was super-expensive, and it really didn't fix anything. And so the problem with all these choices of NoSQL scales forever? It doesn't. All it is, is you don't know when it fails, right? Nothing scales forever. And the problem is that we have things like Postgres, which are decades old. And then we have something that's just like a year and a half old, you're going to run into the problem. That's the problem with these, especially in 2013 and 2014. And that's why it was going up into this over-expectations. And the consultant failed. They had all this hardware. They had to throw all their Cassandra code away. They had to throw all their hardware away. They moved it all into Amazon and then they switched to Amazon DynamoDB. And all of a sudden, it started working just fine. And then they just started writing checks to Amazon because they were going to write checks to consultants and get bad results with Cassandra, or write checks to Amazon and have it work. Now the key to Amazon DynamoDB is it's not magic, you have to learn how it works. But once you learn how it works, you let Amazon upgrade it and do it and performance-tune it, and whatever. And if you are a big enough company, you hire like an Amazon helper from Amazon, and they can look at your stuff and say, you can fix it this way, this, this, this. But the use of the NoSQL database allowed this startup to compete against a much larger firm that was using their own hardware, and just it was really a much larger firm that was building their own data centers and all this stuff and sharding themselves and doing their own sharding. They were not agile because of those choices that they made. And so they were able to compete. And even though their Amazon bills were expensive, it was way cheaper than their competition. And so it's a really good story of NoSQL, but it's also a bad story of NoSQL. And that is, be careful of what you just read on a website to adopt a technology, and that's just a case study. So that's sort of the rise of NoSQL. And the modern interpretation of NoSQL is really just like these are really cool document-style databases that have their purposes. But the ACID vendors have not stayed steady, and we will talk a bit about the reaction to the rise of NoSQL next.

# Reacting to the Rise of NoSQL

So the NoSQL movement comes out of these second-generation, highly complex, pure cloud systems like Facebook, and then a whole bunch of startups that wanted to capitalize on this notion to operate at cloud scale. Everyone wanted to have a single application, which is not a bad thing. But the ACID vendors, who had been doing this for 15, 20 years, some from the 60s and on, they were like, wait a second, you know you upstarts think you know something about database. We actually did learn something in 20 years of database systems. And so they saw in 2013 and 2014 that if they sat down and just said, we're better, that they would lose market share, and there's no question about it. I mean, everybody thought NoSQL was the answer to everything in 2013 and 2014. But the problem is also in 2013 and 2014, those who were using BASE-style databases started to complain because every once in a while, they wanted to do a JOIN. And every once in a while, they would want to do something like a transaction, to do a new account or some billing or whatever. And so what happened was is the NoSQL vendors were hearing complaints. And a lot of vendors tried NoSQL and then ended up with sort of negative results or costly results. And so what happened was is you saw like a rush to ACID plus BASE, right? And if you go back to the database scaling, ACID vendors have had kind of a BASE-like variation, with master and read replica. And the technology didn't stand still either in that decade between 2009 and 2019. Amazon now can, I don't know how they do it, but they can sell you a 32-CPU system with a whole bunch of RAM and talk to slow disks really, really, really fast, and you don't have to own it. So if you want to vertically scale an application, you can. It's not just a carpet cluster anymore. Amazon has done amazing things to give you a wide range, a buffet, of wonderful hardware that you can buy. And the change from spinning disk drives to solid state disk drives is changing everything. I've already mentioned the scatter/gather as a notion, right? Like the Google scatter/gather. Disk drives can now do scatter/gather. And so you can, who knows, by the time you're watching it may be more than 32. But some disk drives, you can say, I want this block and this block and this block and this block and this block, bundle that up into effectively in one message, fire it at the disk drive, and the disk drive is like boop boop boop boop boop, as fast as it can give you those things back, you get all those things back. Now think about a database that has blocks and all the stuff we've talked about how databases work. You can ask for 32 blocks. If you have a little bit of in-memory information and you say give me these 32 blocks, it's as if you asked for one block. It's just like holy mackerel. So the ability to scale relational ACID-based databases has greatly improved in that decade. And so it seemed like every time like a Cassandra or a Mongo would be better, you'd just like, well, I just bought new hardware, and my old-fashioned Postgres is pretty fast.
Play video starting at :3:22 and follow transcript3:22
And so they also had these ACID-style database vendors reacting. They're like, this is kind of easy. We could add this to our stuff pretty easily. And so Oracle added JSON columns, MySQL added JSON columns. Oracle has some kind of a NoSQL database, I don't know as much about Oracle that I don't want to know. But MySQL 8 really is the addition of really cool and flexible JSON columns. I told you why I'm not using MySQL, because I fear that Oracle will bend away from open source. Postgres is pure open source. Postgres has slowly over the years, 2008 through 2014, have been adding. And now we're lucky here that their JSONB, which is by far their most sophisticated sort of aggregate column, came out in 2014. So it's at least five years old. And if we were teaching this course in 2014, we might like say, well, you might not want to use JSONB. But, I mean, today let's use JSONB. And just as an example of this is Amazon has built a data backend, it's just a data lake, basically, called Redshift. And it's like based on Postgres. It's not based on Cassandra. Cassandra, remember, came from Facebook. But Amazon's like, I'm going to build a data lake, and I'm going to grab Postgres. And another thing that's a little less well known is that a little while back, Amazon got rid of all of its Oracle, presumably replacing it with Postgres. Which means that Amazon's own infrastructure, its own billing and its own tracking, uses in effect 100% open source technology. And I think that greatly benefits we in Postgres. Now, Amazon Redshift is based on 8.0, which is before HSTORE, JSON, and JSONB. But I'm going to guess that what they really did was they advanced some of those features separately from the open source community, which more slowly put them in in a way that we can use. To some degree that, you know, and I'm sure Amazon Redshift is a very efficient master-slave replica kind of a thing, because it's really, the Redshift is aimed at kind of a pulling in lots of data simultaneously and a lot of simultaneous readers. And so they probably just tweaked everything. But you still kind of pretend it's SQL. So it turns out that it has been easier for the old-line ACID vendors to add BASE features than it was for the new BASE folks that started distributed to come up with kind of this non-distributed way. And part of it had to do with the master-slave replica model. So the other thing that's happening is it used be that the reason NoSQL doesn't have so much meaning anymore is SQL does not imply ACID. The concept of begin transaction, select for update, etc., yes, that is ACID. To implement that correctly, you have to have ACID. But just the select and the insert and the update, that's neither ACID nor BASE. That's just a syntax. And so the folks got, there was a feeling like SQL was going to die, and that's why they called it NoSQL. And then after they realized SQL was not going to die and that SQL is probably better for 90 to 95% of the applications, they kind of realized, well, let's just kind of join the SQL movement and have a different set of semantics that underlie it in the BASE. So you can either have SQL with ACID semantics or SQL with BASE semantics. And so the runtime is what changes, right? And so you're seeing a trend towards, yeah, here's this completely distributed database, but we got SQL. But don't do a begin transaction, because that won't work very well. because it's really distributed underneath, right? It's shared and distributed underneath. But it makes it so developers can move back and forth. And so I think most applications really these days should start out as ACID-based applications, using something like Postgres, and then they could move to something. But why not, so everyone's going to learn SQL, which was not a foregone conclusion in 2012, that we might, SQL might become like a dinosaur and go away. But it isn't going to be a dinosaur. So now you might as well take these BASE-style database vendors. And for them to support basic SQL is not all that hard, right? They're supporting a subset, and they're clear on what that subset is. But it makes it easier for developers to go back and forth between these things. And so you can kind of imagine that, you know, you've got some hypothetical thing that it might be like Amazon Redshift. I literally don't know anything about this. But you've got some really big vertically scaled ACID master with a transaction log. And you route the SQL transactions that are going to make changes, SQL statements that are going to make changes to that master. And you just use old-school techniques. If you want to do a multi-master, you want to hide that. And then have a bunch of read replicas. And then you could even have a BASE database living right next door that if you're doing just, if you're saying this is a table that doesn't need any ACIDness, and we'll talk about how you might indicate that a table doesn't need ACID capabilities, you might have a completely separate implementation under the covers for inserts and updates into certain tables where you're saying, I'm willing to tolerate eventual consistency, right? And so you can do this all at the SQL level, where you really have, in effect, three databases in the back, and they're talking to one another. And you just create a table, and sometimes it's stored in a ACID database, and with ACID semantics, and sometimes tables are in a store that has BASE semantics. So here's some examples from a really cool blog post that I recommend that you take a look at. And that's how to think in a BASE-like way when using an ACID database. And this is where I'm going to tell you all the rules that I told you before, like not true anymore. So don't normalize. Replicate, right? Don't use SERIAL. It breaks my heart to even tell you these things. Don't use SERIAL. Don't use auto-increment key, right? Because that's a place of commonality that across 10,000 systems, there's no way you can do that. But that's okay, use GUIDs. You randomly pick them in each server, and they're guaranteed to be different, right? Because they include time stamp and a bunch of other random things. So it's like the likelihood of GUID collision is so low that you just basically create the primary key for your new documents that you're putting in.
Play video starting at :9:47 and follow transcript9:47
Fewer columns, not more columns. You have one column called JSONB, which is, you know, a bunch of key-value pairs, which is great. The only, you just like have like a key, an ID, which is a GUID, and then a body, which is JSON. And you'll see some of the stuff I have you do is just like id, JSON. Two things. Now, that doesn't mean you can't have more columns, right? Some columns that are extracts of the JSON. The only time you make a column is for indexing, right? And so now you it's okay to go into Postgres and have exactly two columns, the GUID and the document, or the JSONB document, right? Don't use foreign keys. Or if you do, don't mark them as such, right? Don't, and so you can say this is an integer or this is a GUID that points to. So I'm in like a post, and I want to point to its owner. I could have a column called owner, which is a GUID, not an ID, but don't mark it as a foreign key in the CREATE TABLE. Which means then it doesn't feel it has any need to kind of synchronize across that. It's just a string within the context of this table. And so you have to make sure there's no ON DELETE CASCADE, and there's no ON UPDATE CASCADE, none of that. You don't do that. That's beautifully magic, but it requires ACID for it to work. And so you just don't tell it to do that. You just have some other like process that once you've deleted this thing over here, that like at midnight, it goes and checks to see, it points to a thing that doesn't exist. So can we delete that? And then you delete it, right? So you have maintenance tasks rather than ACID semantics, right? And design your indexes and queries so that you're getting one and exactly one row, right? So it's like document store. There's a lot in that row. You get it all, and then you work with it. And you might say, you might get the row, and then if there's kind of this kind of a pseudo foreign key, you might have to go get that too. And you might do two transactions. But you don't necessarily use a JOIN to do that. You just do two SELECT statements. And that starts to be kind of the semantics of BASE at that point.
Play video starting at :11:53 and follow transcript11:53
And you're relaxing what you're demanding of the database. So when you make a SERIAL column, you're demanding something of the database. You're making a contract with the database that the database has got to comply with. But if you say, no, it's just a GUID, and I'll tell you what it is in my application, I'll make it up in my application and tell you, you take that responsibility away. So the database doesn't have to sort of put that lock up, to put that like barrier that says, Oh, sorry. I've got to wait for everybody else. Hang on, everybody. You've got to wait until this one gets through, right? It's kind of like going down from many lanes to one lane. Well, the SERIAL is going from many lanes to one lane, but the GUID is just many lanes going straight through, and so you just don't have to. So you see? And so the the blog post that's so cool is, we used NoSQL, and then we stopped. We used NoSQL, and then we used BASE-style thinking inside of Postgres, and it turned out to be faster and better. And the fact that Postgres handles really large data sets and has for so long is way better than some of these upstart things that just haven't seen scale. And the problem is now, more and more folks are just using something like Postgres as their NoSQL database. They're careful as they design things, but then they release the constraints. And now what's happening is fewer and fewer folks. And like Amazon Redshift goes to, is Postgres, which just blows my mind in a really good way. So things like software migration, don't use ALTER TABLE. Because ALTER TABLE is itself trying to be transactional. So it's like, lock, lock, lock, lock, lock, lock, lock. No, no, no. Just write a thing that loops through and reads all these things and checks to see if the other thing is there. It might take way longer, and it might be loops instead of SQL statements, but then you're not triggering kind of the ACID nature when you don't need it. Query for record by primary key or index column. Don't read the whole thing, because it's a document store. It's gigantic. Don't use, and again, because you're using the index and the indexes are small, like GUID or something, you're going [SOUND] in like three disk hits or something, and you've got it. Don't use JOINs, even if you have to manually retrieve the other documents. And this is what NoSQL does, right? I mean, you're matching the good and the bad of NoSQL. You've got parallel updates, parallel reads. You've got to read more stuff sometimes. You can't just send a beautiful SQL query. And don't use aggregations. Although I am not sure, I think that, I think I would say this, but I don't have any experience to back me up. I would say don't use aggregations other than COUNT, because, don't use aggregations that.
Play video starting at :14:26 and follow transcript14:26
COUNT can be done. If I was building it, I could build COUNT using an index-only scan, versus like an average, which actually has to retrieve the data. So somehow, my instinct, with no backing, my instinct says COUNT aggregations are different than a max, min, or average aggregation. But someone smarter than me will have to tell you that. So NoSQL is fine, right? NoSQL is doing great. They're realizing that they're more specialized. And there are times when that fire hose of updates is essential. There is less conversation about the end of the SQL language, and more conversation about BASE-style databases adopting it. There is far less, I would almost say no breathless, like, oh, NoSQL is great, great, great, at least people over 30 don't care about it. There is a learning curve. Any time you pick a NoSQL technology, understand that you're going to have to learn. And if you don't know what you're doing and you're starting a company, you're so much better off starting out with a relational database and then adding NoSQL bits to it, rather than just saying I'm NoSQL because I don't feel like learning how to model data. That's the thing that ticks me off the most, is like, if you don't know how to model data and you're going to choose NoSQL because you don't want to learn how to model data. What I want you to do is I want you to learn how to model data, and then say, this is great, except. And then know that not modeling data when it's the right thing to do. Not just because it's lazy and you don't want to learn it. Because modeling data is so beautiful, elegant, and simple. Sorry.
Play video starting at :16:2 and follow transcript16:02
SAAS vendors like Amazon and Google and Azure are really changing the game, because these are multi-tenant natural. The cost can be really much lower than doing your own stuff. And so the idea of hosting your own NoSQL database is, hosting your own database, I'm sorry, your own ACID database, is a normal thing. You know how to manage it, we've done that for decades now. But like figuring out how to make it work, ah, heck, just let Amazon or Google or Microsoft figure that out. Go ahead and Google like move from Mongo to Postgres or move from Mongo to MySQL and you will find that lots of mid-tier pure cloud applications are leaving. Are leaving. They tried it, they built it, they scaled it, and they said, I'm sorry, this just doesn't scale as well as something like Postgres when you don't demand ACID semantics. When you create tables and you use those tables in a BASE-style way, and then you do things like read replicas. So I call your attention to why it is that I picked Postgres for this class. And that is, Postgres is one of the better NoSQL databases, right? And so it, I couldn't have said that in 2012. But now in 2020 and beyond, Postgres is a good choice for NoSQL applications. That doesn't mean it's the choice for all NoSQL applications, or document or key-value store. So Postgres is great. You've learned a lot already about JSON and Postgres and I hope that helps as you go forward making good choices. Cheers. PRODTE9 310

# 