# A GIN-based Inverted Index with PostgreSQL
So I hope you sort of found it a little bit fun to do the inverted indexes the hard way using only SQL statements and inventing our own inverted indexes. But in reality, you don't want to do that. Really the whole purpose of that was so that you understood inverted indexes better. Meaning that you could, if left alone on a desert island with nothing but a many-to-many table, you could make this all work. But now I want to talk about the inverted index that we have built into Postgres and they can do so much more optimization than what we could do with the joins that we were using before and so it's always better to use these indexes. And there's basically two primary inverted indexes. There's a third one that's kind of like SP-GIST which is for spatial data. I wanted it to be like the Special GIST, but it wasn't, it's Spatial for things like data points in a three-dimensional place or latitude and longitude, things like that. So there's two of them, it's called the GIN, the Generalized Index and then there's the GIST, Generalized Search Tree. And just like in B-trees for normal indexes, the prefered text search-type index is just GIN. It has exact matches, it never looks at more rows than it needs to, just like B-trees, it's like this, very like look, find, got a list of rows, pull them in, those are the rows you need. They are very efficient on lookup and search and they can be costly when inserting or updating data, and so sometimes you sort of put all your data in and then you build the GIN later. That's a common technique in these inverted indexes. But if you're just inserting once in a great while, it's not that bad and so it's not terrible. So the GIN is like, if you ever no deep understanding of how you want your indexes to work, just use the GIN, be done with it. The GIST is a sort of reduced size, it uses hashing. And if you remember hashing, hashing throws away information but it makes the calculation simpler, but then more than one thing can hash to the same place and so then you've got extra work when the hash function doesn't spread stuff out the right way. And so it all depends on the nature of the data being hashed, how well the hash function works, but GIST is smaller and it's quicker to update. And so if you're grinding, if you're very update heavy, insert or update heavy, and the query performance is less important than the insert performance, because a lot like, say you're building a blog, right? How often do they put in new blog posts? Like once or twice a day? Fine. The querying it, the searching it, you're going to do over and over again. So the GIN is the fact that the insert is a little more expensive, the GIN. But if you're doing something like watching sort of a Twitter feed or something and pulling data in, and pulling data in, pulling data in, and then once in a while you do a query, well then a GIST is probably the better idea. So it's all really a balance of insert versus query. And a lot of the things in database indexes are a balance between insert and query. The downside of the GIST is that once it passes a value through it, like a word through it, it will get a list of blocks to read and then find rows in that block and it might read more blocks than necessary. The GIN will not read more blocks than necessary, it will read blocks that have the rows, that have the thing in it, that you're looking for. But what the GIST does is it, if it's got extra blocks, it doesn't know that but then it reads the blocks and checks the rows and says "Yeah, because of the hash I pulled in two of them but it's really only in one of them." And so it doesn't actually give you extra rows. You don't have to like add an extra WHERE clause, because within the WHERE clause, it still discards them. So you could think all that the WHERE clause is like, pull stuff in and discard stuff that we don't need. And so it just happens to read a bit more extra from the disk, it doesn't change it. So I'm not really going to spend a lot of time showing you examples of how you use GIST because it works exactly the same as the GIN. You just use it and it's all under the covers and it's all about efficiency and so we don't worry too much about that. So as we'll see later this concept of operations. The GIST and the GIN index know a lot about the data that they're indexing. And again, just like anything in databases, the more precision with which we can describe to the database engine the things that we want to do, the more efficient it can be. And so one of the things that the inverted indexes do is they have what are called operations and they need to know what kind of things they are going to operate and they will build subtly different indexes depending on how it works. Both of them work on arrays, which is sort of like stuff that's long and has pieces within it. That's the best way to think of arrays. And they use this operator, this less than at sign which is like contained within. Is this array overlap this array? So if this array has one thing, two things, or three things. This other array can be very large and if it has those three things among any of those all the things if there's an intersection, that's when it matches. And so let's take a look at how this works and you also tell it, oh, this is an array of integers, this is an array of text, etc. And the thing we're going to do is all based on text. So let's take a little tiny example here that we did in that whole long demonstration before that we did it by hand and it all basically. So we're going to create the exact same table. You can just drop these indexes or drop the tables. I just start each one. I would say DROP TABLE docs, DROP INDEX gin1 if you wanted to when you re-run these over and over and over again. So my examples have those actual drop commands in there. But here's the important thing, right? CREATE INDEX gin1 ON docs USING gin parentheses. And so there's an expression. Now the key here is this expression inside this index creation has got to to match the expression that we're going to use in the WHERE clause, because the WHERE clause is the essential part where we're trying to give a hint to Postgres as to how to throw rows away more quickly. I mean, how to throw blocks away more quickly. Okay, there's 10,000 blocks in here, but because I've used the index, I'm going to pull in three. And so this thing is like thousands of times faster. Right? But I'll admit, it took me a while to get all these things exactly right. But the thing that's important is that when you're making an index and you're making a WHERE clause, that this expressions match perfectly, right? It turns out in the SELECT, there's other things you can put as expressions in the SELECT. They're less significant and you can do more complex things. When we see ranking we're going to see this. The WHERE clause is where the cost of SQL queries happens. So the WHERE clause is very, very, very important. So we're making a generalized index, string_to_array on the column doc split by spaces and we're going to use text operators, okay? And that's just matching strings, okay? At this point, we're not doing natural language. We're going to do natural language in a bit, okay? And so this is really a very crude, very pure string-based, kind like a split. What you might do in Python to turn a stuff with blanks in it into literal strings. There's no sense that this is actual language, even though the examples I'm using are language, there is no understanding of language. We'll see that when we do this next. So we're saying okay, let's make an index and let's insert some stuff. And like always, the index is just being built while the inserts are happening and the index magically happens. And then we can do a SELECT and the key thing to this SELECT is it's using this less than at sign operator. So we have to pass our constant, as it were, to say "oh, here's an array." So that curly brace, learn, curly brace is a one-element array with the string learn in it, that's what that syntax is. I mean, technically that's curly brace, learn, double colon, text, open bracket, close bracket, which is converting it to a text array, but it's an array of one item. So that's kind of the serialized form of a text array. And then string_to_array of doc, this is to say, "Oh, remember that index I just made? You could run this on every row and then do the string_to_array on every row and check the WHERE clause. Or the fact that you've done an index and it gives you a clue to what rows you're dealing with." Right? So we can do an EXPLAIN on this same query. So if you do a query, it just happens and gives you the rows you're supposed to get with the word learn in it, The EXPLAIN, and it doesn't, let's see, how many, do we have any other? No. So you can do a EXPLAIN and that tells you the query plan and the key thing when you're looking at these query plans is again, it takes me a while to debug these. Just because I have these done in an instant in these lectures doesn't mean that it didn't take me a little while and some Googling and some Stack Overflowing to figure this out. But what you don't want to see is sequential scan. When you see sequential scan, that means that you failed. That means that you made this cool index, but whatever your WHERE clause was, it didn't activate the index. Because that's what you're trying to get. Now Heap Scan, Recheck, Index Scan, all those are good things and that's what you want to see that basically says that you have successfully made an index and you've successfully made a query that uses those index. And if this thing matters, you will take every query that you were ever going to use that you expect to use that index and you'll do an EXPLAIN on it to make sure that you're getting it right. So that's a lot of talk about very few lines. I mean, if you go through this, it's just like two lines that matter. It's the creating of the index and the array expression inside that index, and then there's the WHERE clause that uses the less than at sign. And so it's very simple, it's very elegant. You will find this so easy to use that you'll like use it whenever you need it and just say "Thank you very much, Postgres, for putting all this work in." So up next. Up next, clear all that. Up next, we're going to start switching from pure string indexes to natural language indexes. Okay? 

# Demonstration: GIN-based inverted index
So now we're going to do the inverted index in Postgres. And it just turns out it's a whole bunch easier to do it in Postgres because we're just going to use the GIN index. So let's take a look at the 05-FullText.sql document. And so let's go ahead and make our docs table. If you already created it, if you're doing this like one edit in a multiple at a time, then you can drop the table and drop the indexes. It's always a good idea. I don't have one. Now, there are two ways to create this index. You might be using Postgres 9 and you might be using Postgres 11. Let's check to see which one I'm doing. Select version (). Hey, I'm Postgres 11. So that means that I have to use this, I have to use the array_ops. Now what happened is between Postgres 9 and Postgres 11, they sort of merged a lot of array types into one array_ops, and so life got a lot simpler. You didn't have to tell it the type. So I'm going to make this as my index, so CREATE INDEX gin1 ON docs USING gin string_to_array doc double quote and array_ops is the operator class.
Play video starting at :1:21 and follow transcript1:21
So I'm going to do that. So I've created a table and I'm going to create the index. So you can think of this as it understands that this, the index is breaking the document into an array. And then we have to be able to do array operations on it, which you'll see in a moment what array operations are. So I've created the index. I'm going to throw some documents in. It's the same documents. And then I'm going to throw some filler lines. So INSERT INTO docs I'm going to use the generate_series to throw 10,000 more lines in. And that's because sometimes it won't use the index unless it's big enough. And as matter of fact, we might find that the EXPLAIN doesn't work yet. Let me try it real quick. Yeah, so that's a sequential scan. And so the problem is, is it's actually still at this moment while we're watching it it is working on it just got 10,000 records inserted, and it's actually in the background. The index is sort of out of date, and the index is catching up. And so it takes a while. So, we'll come back to that in a second, we'll run it. So, let's look at this.
Play video starting at :2:39 and follow transcript2:39
Let us look at that SELECT id generate_series INSERT INTO docs, right? INSERT INTO docs and then there is a SELECT and then this is just Neon concatenated with generate_series. generate_series is sort of a vertical expansion that's going to create a series of rows, Neon 10000 and Neon 10001, Neon 10,002 and that puts 10,000 rows in our database. So if it was to do a SELECT count star FROM docs, you will see that there is 10,004 records in, and that is the three I put in, and then the 10,001 that it put in later, okay? So that's the generate_series, but we talked about that earlier. And let's do this SELECT. Now this is an array. You can kind of say is this learn array contained within the string_to_array of doc? Now the key thing to anything in an index is the WHERE clause is where the index heavy lifting happens. And the key is to match what you're making the index on to what you're checking against in the WHERE clause. So the fact that string_to_array doc with a space and array_ops, that is the thing we've got to have in the WHERE clause. And, of course, quote curly brace learn quote curly brace quote. That is a one-element string array in Postgres syntax. So we'll go grab that and find the docs. And so we've found that one, SELECT id, now let's just, the EXPLAIN has caught up. And after I blah blah blah long enough, yay! The EXPLAIN caught up, so don't feel bad if your EXPLAIN takes a while. So we did the same EXPLAIN, we didn't do anything except waited. So what happened there was because we inserted 10,001 records, it was out of date and so it said, you know, my index isn't quite right, I'm not going to trust it. I'm going to wait until the index catches up. This is one of the issues of inverted indexes. If you're under a heavy insert load, the poor index never catches up or it costs you a lot of effort and the index is always behind so you're not using it. So if you're continuously inserting, then you might never be able to use the index, because it's always marked as like incomplete. It has to kind of catch back up. So there's a bunch of re-organization that has to happen. But in this particular one, it worked just peachy, okay? And so that's pretty much it. You did that, it's really not that much work. You create the index, you get the index expression right, you pick your operator class. And then at some point your EXPLAINs start to work, okay? So I hope you find that helpful, cheers.

# Building a Natural Language Index in PostgreSQL

So that was pretty complex, and I hope you learned some SQL and had a little bit of fun, knowing that you did not have to depend on Postgres for your text inverted language-aware natural language index using GIN and all these other things. But the reality is, as we well know, the easy way to do this is just to let Postgres do all the hard work. Postgres already knows all these languages and away it goes. So let's talk about the concepts required that you need to understand, and then how you make these indexes work. So there are two really important functions, and they are actually data types as well. There's this notion of a ts_vector. So the ts_vector is a text string vector.
Play video starting at ::50 and follow transcript0:50
I don't know if I should explain why they're call it vector, I guess I will explain why they call it vector.
Play video starting at ::58 and follow transcript0:58
If this next thing doesn't make sense to you, don't get too excited about it. I'm not going to ask you this like on an exam or anything. So the idea is, is you place a document in a n-dimensional space. Right here, I've got a three-dimensional space because we got a little bad three-dimensional space that I've written, and so you can take and put things at various places in this three-dimensional space, and then you're kind of looking for closeness in three-dimensional space. And that's how you do it, but it's not just three dimensions, it's n-dimensional. And so this vector is the vector from the origin to the particular document that you've got, and so you're trying to cluster in a n-dimensional space. And if none of that made any sense to you, don't worry about it. It really doesn't matter. But that's why they call them vectors. You could also think of it as it's a fancy array, because a vector is a sort of a fancy array. So there is this function in Postgres called to_tsvector, and you'll notice that it takes two parameters. The first parameter is the language that we're working. Remember, I told you how important language is, and we all showed you that there are many languages that Postgres already knows. I'm just happening to be using English, and then the string. So that basically says, hey, that's an English string. Let's extract its features. Let's extract the nature of that string, stemming, case, etc., eliminating stop words. That's all in there. Right there is all the work we did with stemming and all that stuff. It also keeps track of the locations and there's a whole chunk of weighting that we don't have to worry about, but there's weighting, and that might have to do with you want to weight the title more than you want to weight the description. You can even concatenate rows together. I mean concatenate columns together to kind of create metacolumns, but really all it does is it extracts the essential features of a phrase or a document of text and the positions. And so you'll see later when we get to ranking that the position matters a little bit. And you can even have things like, I want to search for Python followed by SQL, or SQL followed by Python. Now, in this particular that's probably a bad search, but the ordering can matter. And so these ts_vectors keep track of the order of the things in the document. If you watch the Matt Cutts video, you'll see that sometimes if you say Python SQL and it's closer together, that actually means more than if it's farther apart. So distance between the words, if you're searching for more than one word. Okay? And so that's what the ts_vector does. And the ts_vector generally is the thing that we index on. So if we go back to what we did before, we indexed on a string array. So now we're indexing on this ts_vector, and Postgres knows everything there is to know about ts_vectors because they invented them, and the indexes are very smart about ts_vectors, okay? And then when we're going to do a WHERE clause, we create a thing called a ts_query. And the ts_query basically says, break, apply stemming rules, apply language rules, apply stop word rules. You can have more than one word. This is a real simple one, and you can see in this case when I do a SELECT to_tsquery english teaching, you see that the result is a stemmed version of the word teaching. So teaching stems down to teach. And so you can also see that the stem happened from UMSI teaches Python SQL, the teaches stemmed down to teach. But then in the query, we've got to stem it down as well. It turns out this whole idea of stemming of the queries, there's a technical term for that and it's in one of these Wikipedia things. It's called conflation. I don't exactly know why they picked that. That's a cool word. I've never used conflation in a sentence. So the applying of the stemming rules from a ts_query, from the input to the ts_query to the output of the ts_query, is using conflation. So I get to use conflation in a sentence. So that's called conflation. And so then what we do to make a WHERE clause is we combine, the most typical WHERE clause, is to combine a ts_query and a ts_vector. And you could actually say, is this ts_vector equal to that ts_vector. That works too. But this double at-sign operator is the cool thing. And you basically say, hey here's a query, to_tsquery english teaching. Is that sort of contained within the to_tsvector in English of UMSI also teaches Python and SQL. And in that case, it's true. So it says that query matches that text, even though teaching is not in the string, but teaches is in the string. So you see how this sort of softer but clever matching is there. So I think that's pretty cool, and just show ts_vector takes any document, reduces it to its essence including position, and then ts_query takes any string and reduces it to its essence in a way that can be matched to a ts_vector. You did this the hard way in SQL, now we're going to do it the easy way in Postgres. So we're going to create our same table, docs with just one column of a document, and then we're going to create GIN using to_tsvector, that was that function that converts a column into a smart array with all the stemming, etc., etc.,and we have to tell it what language we're dealing with. That's why you need to know which language these things are, and you'll notice that this is actually simpler than the string one. Because I didn't have to say the operators. And that's because like the GIN and the ts_vectors are good friends and they know what's going on. There's some ops for it, but it's like, oh, it's a ts_vector. I know what you're going to be doing. You're going to be doing the double at-sign operator. I know exactly what you want to do. Here you go. I'm taking care of it. So this is in a way. The natural language is simpler than the pure string generalized index. And we're just using GIN. You could use GIST. Again, going back to that, just use GIN unless you have a reason to use GIST. So we throw some things in there, and it fills up the index, and then we're doing a WHERE clause, and we can say to_tsquery english learn @@ to_tsvector english doc. Now again, if this didn't have an index, we would simply retrieve every row, compute the to_tsvector, and then check to see if it double added the ts_query. But that's not what we want. And of course, we find the row, row 2 is the one that matches the learn, right?
Play video starting at :7:43 and follow transcript7:43
And then if we do an EXPLAIN on it to_tsquery, EXPLAIN SELECT id doc FROM docs WHERE to_tsquery english comma learn, double at-sign to_tsvector english doc, that is where it's a WHERE clause, and the WHERE clause matches the expression that's in the WHERE clause with the expression that was in the index and says, you know what, I can use that index. And so that's again when you fail and get a sequential scan, sequential scan is not our friend. No sequential scan, but instead we got a nice little index scan, heap scan, anything but sequential scan in general is a success. And so again, you're going to do this, and you do these over and over and over in little sample examples until you get it right, and then you're going to want to do an EXPLAIN on every single query that you're using to make sure you sort of didn't fall apart, right? You didn't like add an AND clause, or who knows what it is that you're going to do, okay? So that pretty much gets us to the point where we have created a index, and we can query that index, and it was pretty easy. Up next we're going to see how you're going to rank the results. Again, kind of taking a cue from Google and the other search engines.

# Demonstration: Fulltext tsquery and tsvector Functions
So now that we've explored doing some of the stop words and stemming using SQL natively, we're going to do the much easier way of doing this by building on the Postgres capabilities and their stemming and stop words and their ability to store this data very densely far surpasses our ability because they can build indexes specifically for this kind of stuff and they can tweak it and have extensive stop word lists. So really what I just showed you with the docs_gin was just to give you a sense of the kind of basic data structures that Postgres is going to make on our behalf. Now, before we get into how to do it, turns out how to do it's not hard at all. There are two really important functions. So in the previous examples, we were using string_to_array to split strings into words. There is a language-aware function, two functions called ts_vector and ts_ query, that basically take strings and turn them into an internal structure. And so this select to_tsvector, you'll notice that we have to tell it what language it is because then it's picking a dictionary for stemming and stop words and other kinds of tuning. And what that does is it goes and does the stemming and stop words and tells you along with the position the non thrown away stuff. So you'll notice that and is thrown away. And you can see the stemming if we say to_tsquery in teaching. You can see that teaching is stemmed down to teach, just like what we did in the previous example. And so then in the WHERE clause, so the ts_query is a thing you're looking for and ts_vector is a thing that you're indexing. Okay? And this function to_tsvector and to_tsquery converts using a language to either a ts_vector or a ts _query object unless ts_query doesn't have a position in there. These are the positions. Also is twice in positions two and six, Python is in fourth position, SQL's in seventh position, teaches. That's what those numbers are telling you. We use this at, double at-sign operator which is really is if you think of it, you can put various things on one side but I think of it as like left side ts_query, right-side ts_vector. It returns a true or a false. So let's go ahead and run these commands. Again, I'm using the
Play video starting at :2:43 and follow transcript2:43
www.pg4e.com/lectures/05-FullText.sql for the samples, we can run some to_tsvector commands. I'll just copy all three of these to_tsvector commands.
Play video starting at :2:58 and follow transcript2:58
So these selects that have no tables, they're just kind of running the functions and you'll see like people's been stemmed, learn. The stop words are all happening. And so there you go. So that's the to_tsvector. ts_query, you can see some stemming going on. Let's grab these next four. I'm going to do a to_tsquery of teaching teaches in English, so teaching as a query is teach, teaches as a query is teach. So that's two examples of stemming. And if we do a to_tsquery of the word and, it complains, "Hey, don't put only stop words." So I put a stop word. And is a common stop word. But you'll also know that and you do a to_tsquery on something like SQL, which it doesn't have a stem for, and it's not a stop word, it just converts it to lowercase and gives it to us. Now again, we worked really hard to build all this in SQL with like five six-line-long SELECT statements, and the to_tsquery does all this for us. So that's quite nice. So you can also put logical operators, the to_tsquery with a vertical bar that's or, or, or, or, or. And so you can think of this ts_query being sent to the database. I wish it would be clever enough to realize that teach or teach or teach or teach. You see that it's stemmed, it's lowercase, it threw away stop words, and it's basically it should really just say teach, but teach or teach or teach. These ts_queries, you can think of them as being sent to the database like, "Hey database, you have all these documents. We're going to hand you this query." It's a parsed query. It's like a compiled query. We're firing it into the database and the database is going to scan the rows or, if all goes well, it'll use the index instead. Now, there's a couple of different ways to do this. There is plain text to_tsquery like in this case plainto_tsquery of SQL and let me grab both of them.
Play video starting at :5:5 and follow transcript5:05
This one I don't like so much because this imples all the words happen, it implies and. And, of course, it's doing stemming. But if you do this plainto_tsquery, that implies and between all of the operators. There is a phrase, and that basically says we want phraseto_tsquery says I would want to see SQL followed by Python, and again, stemmed in lowercase. If you are Postgres 11 or later, which I happen to be in this particular one, you can do websearch_to_tsquery. Now, websearch_to_tsquery uses a syntax that I think was pioneered by Google. It's got a couple of special things in there. It also tolerates. It does something if you have like a syntax error, it doesn't freak out and you're kind of expected that this can be typed by the user and not blow the system up. Some of these things like plainto_tsquery or to_tsquery, you can type syntax errors in the query. So you have to be careful, but the phraseto and the websearch_to don't need that. So we can ask whether or not a particular query is inside of a particular text vector. And this is kind of where you're stemming and stop wording. So you have to stem and stop word the query and then you have to stem and stop word the thing that you're querying. So we'll stop here, but then up next, we're going to show how you actually do the index using these functions.

# Demonstration: Building a GIN / tsvector Index
So now we're going to get the payoff. We're going to actually make a natural language inverted index with Postgres. And it's way simpler than everything I've done so far. Again, the key is you have to understand where the ts_vector works and how the ts_query works. But once you understand what those do, stemming, stop words, etc., it's pretty straightforward. And again, I'm working from www.pg4e.com/lectures/05-FullText.sql. So I don't know, I might have to drop this table. We'll drop the index. And then we will recreate them. And did not exist. So we'll create our documents which again, has just an id and a document text field. And then we're going to create a, this is the critical one, we're going to create an index named gin1 on the docs table using the gin and the index expression is to_tsvector quote english quote comma doc. So that says take the document column, run it through a ts_vector with the English
Play video starting at :1:11 and follow transcript1:11
dictionary, and then give me a reverse index for everything that makes it through. Stop words, lowercase, and stemming are all done. So if you look at this, the earlier thing I did that was just strings was actually harder than doing an inverse index. So I'm just going to run it. And I'm going to insert some rows, insert my three rows in there. And then I'm going to insert some filler rows to make sure that that Postgres knows we're serious. So I did the generate_series insert 10,001 rows of Neon, and some numbers.
Play video starting at :1:48 and follow transcript1:48
And remember, it might take some time.
Play video starting at :1:53 and follow transcript1:53
It might take some time to get things to work, so I can do a SELECT id doc FROM docs WHERE to_tsquery matches the to_tsvector of english doc. And again, look at the WHERE clause and the expression that's being indexed is to_tsvector using English dictionary, the doc. That is exactly the same as what's inside of the gin expression, right? So we created the index, that expression. So we generally know that the kinds of things that are going to use the indexes are the ones that end like that. Now you can create more than one index. And you can create more than one index with more than one expression. You can do a lot of things with these things. But of course the cost of the inserts and the queries, how much space the index is taking, how much cost for each index. And let's go ahead and see if our index, while I was talking, blah blah blah blah blah. Let's do a query EXPLAIN just to see if it's made it yet. Yep, all the inserts in that time frame, it was able to process 10,001 documents and insert them. So let's do something really, I don't know if it'll be interesting or not.
Play video starting at :3:18 and follow transcript3:18
Probably not, so let's just try it, let's just try it. So we're going off the script a little bit. So I got this CREATE INDEX gin1. I'm going to DROP INDEX gin1, so now it's gone. Yeah, DROP INDEX gin1. Index is just data that the database has, so you can get rid of them. And now I'm going to do my EXPLAIN. Away it goes, okay?
Play video starting at :3:48 and follow transcript3:48
So now, I am going to create a GIST index that does the exact same thing. I'm going to copy this line, CREATE INDEX gin1 ON docs. And the only change I'm going to do is on the USING, I'm going to say USING GIST.
Play video starting at :4:4 and follow transcript4:04
Now, the thing about the GIST is that it is.
Play video starting at :4:8 and follow transcript4:08
And by the way, all those rows are still there. We still have 10,004 rows in. So the question is, how fast can a GIST vector a GIST in an inverted search tree? How fast can Postgres make one of those, versus how fast it can make GIN? because the main advantage of GIST is that it's easier and quicker to make and maintain. And it's smaller, but you might have to retrieve a few more blocks of data.
Play video starting at :4:39 and follow transcript4:39
So what I want to do is create the index and then see sort of how long it takes before the EXPLAIN starts to work. So the EXPLAIN. The EXPLAIN instantly worked. Do you see that? As fast as I could type it, the GIST was there. Now let's do it again. DROP INDEX gin1.
Play video starting at :4:59 and follow transcript4:59
Get rid of that one. Now it's gone. Now I'm going to make a GIN index and we will see if we can catch it. Having not yet been indexed. So I just made it a GIN, the index expression is the same. GIN and GIST both know this ts_vector like perfectly. So I'm going to create it and then I'm up then I'm going to do an EXPLAIN SELECT again. Boom, boom, boom, EXPLAIN SELECT. Ah, it was too fast for me, so I didn't get to show you.
Play video starting at :5:28 and follow transcript5:28
It made the GIN really fast as well. But I wish I could have showed you that the GIST happens faster than the GIN. And you get the same rows back, because the GIN takes care of all of that. So it's really quite straightforward. The goal is to get to the point where your EXPLAIN doesn't do a sequential scan. That's all we're trying to do, okay? So I hope you found this useful. Cheers!

# 